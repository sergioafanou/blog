---
layout: post
title: Cómo crear un clúster de Kubernetes usando Kubeadm en Ubuntu 18.04
network: digitalocean
date: January 09, 2020 at 05:46PM
url: https://www.digitalocean.com/community/tutorials/how-to-create-a-kubernetes-cluster-using-kubeadm-on-ubuntu-18-04-es
image: http://ifttt.com/images/no_image_card.png
tags: docker
feedtitle: DigitalOcean Community Tutorials
feedurl: https://www.digitalocean.com/community/tutorials
author: DigitalOcean
---
<p><em>El autor seleccionó la <a href="https://www.brightfunds.org/funds/foss-nonprofits">Free and Open Source Fund</a> para recibir una donación como parte del programa <a href="https://do.co/w4do-cta">Write for DOnations.</a></em></p>

<h3 id="introducción">Introducción</h3>

<p><a href="https://kubernetes.io">Kubernetes</a> es un sistema de orquestación de contenedores que administra contenedores a escala. Fue inicialmente desarrollado por Google en base a su experiencia en ejecución de contenedores en producción, es de código abierto y una comunidad mundial impulsa su desarrollo de manera activa.</p>

<p><span class='note'><strong>Nota:</strong> Para este tutorial se utiliza la versión 1.14 de Kubernetes, la versión oficial admitida en el momento de la publicación de este artículo. Para obtener información actualizada sobre la versión más reciente, consulte las <a href="https://kubernetes.io/docs/setup/release/notes/">notas de la versión actual</a> en la documentación oficial de Kubernetes.<br></span></p>

<p><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/">Kubeadm</a> automatiza la instalación y la configuración de componentes de Kubernetes como el servidor de API, Controller Manager y Kube DNS. Sin embargo, no crea usuarios ni maneja la instalación de dependencias al nivel del sistema operativo ni su configuración. Para estas tareas preliminares, se puede usar una herramienta de administración de configuración como <a href="https://www.ansible.com/">Ansible</a> o <a href="https://saltstack.com/">SaltStack</a>. El uso de estas herramientas hace que la creación de clústeres adiciones o la recreación de los existentes sea mucho más simple y menos propensa a errores.</p>

<p>A través de esta guía, configurará un clúster de Kubernetes desde cero usando Ansible y Kubeadm y luego implementará una aplicación de Nginx en contenedores.</p>

<h2 id="objetivos">Objetivos</h2>

<p>Su clúster incluirá los siguientes recursos físicos:</p>

<ul>
<li><strong>Un nodo maestro</strong></li>
</ul>

<p>El nodo maestro (un <em>nodo</em> de Kubernetes hace referencia a un servidor) se encarga de administrar el estado del clúster. Ejecuta <a href="https://github.com/coreos/etcd">Etcd</a>, que almacena datos de clústeres entre componentes que organizan cargas de trabajo en nodos de trabajo.</p>

<ul>
<li><strong>Dos nodos de trabajo</strong></li>
</ul>

<p>Los nodos de trabajo son los servidores en los que se ejecutarán sus <em>cargas de trabajo</em> (es decir, aplicaciones y servicios en contenedores). Un trabajador seguirá ejecutando su volumen de trabajo una vez que se le asigne, incluso si el maestro se desactiva cuando la programación se complete. La capacidad de un clúster puede aumentarse añadiendo trabajadores.</p>

<p>Tras completar esta guía, tendrá un clúster listo para ejecutar aplicaciones en contenedores siempre que los servidores del clúster cuenten con suficientes recursos de CPU y RAM para sus aplicaciones. Casi cualquier aplicación tradicional de Unix que incluya aplicaciones web, bases de datos, demonios y herramientas de línea de comandos pueden estar contenedorizadas y hechas para ejecutarse en el clúster. El propio clúster consumirá entre 300 y 500 MB de memoria y un 10 % de CPU en cada nodo.</p>

<p>Una vez que se configure el clúster, implementará el servidor web <a href="https://nginx.org/en/">Nginx</a> para que garantice que se ejecuten correctamente las cargas de trabajo.</p>

<h2 id="requisitos-previos">Requisitos previos</h2>

<ul>
<li><p>Un par de claves SSH en su máquina local Linux/macOS/BSD. Si no ha usado claves SSH antes, puede aprender a configurarlas siguiendo <a href="https://www.digitalocean.com/community/tutorials/ssh-essentials-working-with-ssh-servers-clients-and-keys#generating-and-working-with-ssh-keys">esta explicación para configurar claves SSH en su máquina local</a>.</p></li>
<li><p>Tres servidores con Ubuntu 18.04 y menos 2 GB de RAM y 2 vCPU cada uno. Debería poder usar SSH en cada servidor como usuario root con su par de claves SSH.</p></li>
<li><p>Ansible instalado en su máquina local. Si usa Ubuntu 18.04 como SO, siga la sección &ldquo;Paso 1: Instalar Ansible&rdquo; en <a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-ansible-on-ubuntu-18-04#step-1-%E2%80%94-installing-ansible">Cómo instalar y configurar Ansible en Ubuntu 18.04</a> para instalar Ansible. Para acceder a instrucciones de instalación en otras plataformas, como macOS o CentOS, siga la <a href="http://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html#installing-the-control-machine">documentación de instalación oficial de Ansible</a>.</p></li>
<li><p>Conocimiento de los libros de reproducción de Ansible. Para revisarlo, consulte <a href="https://www.digitalocean.com/community/tutorials/configuration-management-101-writing-ansible-playbooks">Introducción a la administración de configuración 101: Escribir playbooks de Ansible</a>.</p></li>
<li><p>Conocimientos sobre cómo iniciar un contenedor desde una imagen de Docker. Vea el &ldquo;Paso 5: Ejecutar un contenedor de Docker&rdquo; en <a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-18-04#step-5-%E2%80%94-running-a-docker-container">Cómo instalar y usar Docker en Ubuntu 18.04</a> si necesita un repaso.</p></li>
</ul>

<h2 id="paso-1-configurar-el-directorio-de-espacio-de-trabajo-y-el-archivo-de-inventario-de-ansible">Paso 1: Configurar el directorio de espacio de trabajo y el archivo de inventario de Ansible</h2>

<p>En esta sección, creará un directorio en su máquina local que funcionará como su espacio de trabajo. Configurará Ansible localmente para que pueda comunicarse con comandos y ejecutarlos en sus servidores remotos. Una vez realizado esto, creará un <code>archivo de hosts</code> que contenga información de inventario como las direcciones IP de sus servidores y los grupos a los que pertenece cada servidor.</p>

<p>De sus tres servidores, uno será el maestro con un IP que se mostrará como <code><span class="highlight">master_ip</span></code>. Los otros dos servidores serán trabajadores y tendrán los IPS <code><span class="highlight">worker_1_ip</span></code> y <code><span class="highlight">worker_2_ip</span>.</code></p>

<p>Cree un directorio llamado <code>~/kube-cluster</code> en el directorio de inicio de su máquina local y <code>cd</code> en él:</p>
<pre class="code-pre command local-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="$">mkdir ~/kube-cluster
</li><li class="line" prefix="$">cd ~/kube-cluster
</li></ul></code></pre>
<p>Este directorio será su espacio de trabajo para el resto del tutorial y contendrá todos sus libros de reproducción de Ansible. También será el directorio dentro del que ejecutará todos los comandos locales.</p>

<p>Cree un archivo llamado <code>~/kube-cluster/hosts</code> usando <code>nano</code> o su editor de texto favorito:</p>
<pre class="code-pre command local-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="$">nano ~/kube-cluster/hosts
</li></ul></code></pre>
<p>Añada el siguiente texto al archivo, que especificará información sobre la estructura lógica de su clúster:</p>
<div class="code-label " title="~/kube-cluster/hosts">~/kube-cluster/hosts</div><pre class="code-pre yaml local-environment"><code langs="">[masters]
master ansible_host=<span class="highlight">master_ip</span> ansible_user=root

[workers]
worker1 ansible_host=<span class="highlight">worker_1_ip</span> ansible_user=root
worker2 ansible_host=<span class="highlight">worker_2_ip</span> ansible_user=root

[all:vars]
ansible_python_interpreter=/usr/bin/python3
</code></pre>
<p>Es posible que recuerde que <a href="http://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html"><em>los archivos de inventario</em></a> de Ansible se utilizan para especificar datos del servidor, como direcciones IP, usuarios remotos y las agrupaciones de servidores que se abordarán como una sola unidad para ejecutar comandos. <code>~/kube-cluster/hosts</code> será su archivo de inventario y usted agregó a este dos grupos de Ansible (<strong>maestros *<em>y *</em>trabajadores</strong>) para especificar la estructura lógica de su clúster.</p>

<p>En el grupo de <strong>maestros</strong>, existe una entrada de servidor llamada &ldquo;master&rdquo; que enumera el IP del nodo maestro (<code><span class="highlight">master_ip</span></code>) y especifica que Ansible debería ejecutar comandos remotos como usuario root.</p>

<p>De modo similar, en el grupo de <strong>trabajadores</strong>, existen dos entradas para los servidores de trabajo <code><span class="highlight">worker_1_ip</span></code> y <code><span class="highlight">worker_2_ip</span></code> que también especifican el <code>ansible_user</code> como root.</p>

<p>La última línea del archivo indica a Ansible que utilice los intérpretes de Python 3 de servidores remotos para sus operaciones de administración.</p>

<p>Guarde y cierre el archivo después de agregar el texto.</p>

<p>Tras haber configurado el inventario del servidor con grupos, instalaremos dependencias a nivel del sistema operativo y crearemos ajustes de configuración.</p>

<h2 id="paso-2-crear-un-usuario-no-root-en-todos-los-servidores-remotos">Paso 2: Crear un usuario no root en todos los servidores remotos</h2>

<p>En esta sección, creará un usuario no root con privilegios sudo en todos los servidores para poder acceder a SSH manualmente como usuario no privilegiado. Esto puede ser útil si, por ejemplo, desea ver la información del sistema con comandos como <code>top/htop</code>, ver una lista de contenedores en ejecución o cambiar archivos de configuración pertenecientes a root. Estas operaciones se realizan de forma rutinaria durante el mantenimiento de un clúster, y el empleo de un usuario no root para esas tareas minimiza el riesgo de modificar o eliminar archivos importantes o de realizar de forma no intencionada otras operaciones peligrosas.</p>

<p>Cree un archivo llamado <code>~/kube-cluster/initial.yml</code> en el espacio de trabajo:</p>
<pre class="code-pre command local-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="$">nano ~/kube-cluster/initial.yml
</li></ul></code></pre>
<p>A continuación, añada el siguiente <em>play</em> al archivo para crear un usuario no root con privilegios sudo en todos los servidores. Un play en Ansible es una colección de pasos que se deben realizar y se orientan a servidores y grupos específicos. El siguiente play creará un usuario sudo no root:</p>
<div class="code-label " title="~/kube-cluster/initial.yml">~/kube-cluster/initial.yml</div><pre class="code-pre yaml local-environment"><code langs="">- hosts: all
  become: yes
  tasks:
    - name: create the 'ubuntu' user
      user: name=ubuntu append=yes state=present createhome=yes shell=/bin/bash

    - name: allow 'ubuntu' to have passwordless sudo
      lineinfile:
        dest: /etc/sudoers
        line: 'ubuntu ALL=(ALL) NOPASSWD: ALL'
        validate: 'visudo -cf %s'

    - name: set up authorized keys for the ubuntu user
      authorized_key: user=ubuntu key="{{item}}"
      with_file:
        - ~/.ssh/id_rsa.pub
</code></pre>
<p>Este es un desglose de lo que hace este libro de reproducción:</p>

<ul>
<li><p>Crea el usuario no root <code>ubuntu</code>.</p></li>
<li><p>Configura el archivo <code>sudoers</code> para permitir que el usuario de <code>ubuntu</code> ejecute comandos <code>sudo</code> sin un mensaje de contraseña.</p></li>
<li><p>Añade la clave pública de su máquina local (por lo general <code>~/.ssh/id_rsa.pub</code>) a la lista de claves autorizadas del usuario <code>ubuntu</code> remoto. Esto le permitirá usar SSH en cada servidor como usuario <code>ubuntu</code>.</p></li>
</ul>

<p>Guarde y cierre el archivo tras haber añadido el texto.</p>

<p>A continuación, ejecute el libro de reproducción ejecutando lo siguiente a nivel local:</p>
<pre class="code-pre command local-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="$">ansible-playbook -i hosts ~/kube-cluster/initial.yml
</li></ul></code></pre>
<p>El comando se completará en dos o cinco minutos. Al finalizar, verá resultados similares al siguiente:</p>
<pre class="code-pre  local-environment"><code langs=""><div class="secondary-code-label " title="Output">Output</div>PLAY [all] ****

TASK [Gathering Facts] ****
ok: [master]
ok: [worker1]
ok: [worker2]

TASK [create the 'ubuntu' user] ****
changed: [master]
changed: [worker1]
changed: [worker2]

TASK [allow 'ubuntu' user to have passwordless sudo] ****
changed: [master]
changed: [worker1]
changed: [worker2]

TASK [set up authorized keys for the ubuntu user] ****
changed: [worker1] =&gt; (item=ssh-rsa AAAAB3...)
changed: [worker2] =&gt; (item=ssh-rsa AAAAB3...)
changed: [master] =&gt; (item=ssh-rsa AAAAB3...)

PLAY RECAP ****
master                     : ok=5    changed=4    unreachable=0    failed=0   
worker1                    : ok=5    changed=4    unreachable=0    failed=0   
worker2                    : ok=5    changed=4    unreachable=0    failed=0   
</code></pre>
<p>Ahora que la configuración preliminar está completa, puede instalar dependencias específicas de Kubernetes.</p>

<h2 id="paso-3-instalar-las-dependencias-de-kubernetetes">Paso 3: Instalar las dependencias de Kubernetetes</h2>

<p>A través de esta sección, instalará los paquetes a nivel del sistema operativo requeridos por Kubernetes con el administrador de paquetes de Ubuntu. Estos paquetes son l:</p>

<ul>
<li><p>Docker: un tiempo de ejecución de contenedores. Es el componente que ejecuta sus contenedores. La compatibilidad con otros tiempos de ejecución como <a href="https://coreos.com/rkt/">rkt</a> se encuentra en etapa de desarrollo activo en Kubernetes.</p></li>
<li><p><code>kubeadm</code>: herramienta de CLI que instalará y configurará los distintos componentes de un clúster de forma estándar.</p></li>
<li><p><code>kubelet</code>: servicio o programa del sistema que se ejecuta en todos los nodos y gestiona operaciones a nivel de nodo.</p></li>
<li><p><code>kubectl</code>: una herramienta de CLI que se utiliza para emitir comandos al clúster a través de su servidor de API.</p></li>
</ul>

<p>Cree un archivo llamado <code>~/kube-cluster/kube-dependencies.yml</code> en el espacio de trabajo:</p>
<pre class="code-pre command local-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="$">nano ~/kube-cluster/kube-dependencies.yml
</li></ul></code></pre>
<p>Añada los siguientes play al archivo para instalar estos paquetes a sus servidores:</p>
<div class="code-label " title="~/kube-cluster/kube-dependencies.yml">~/kube-cluster/kube-dependencies.yml</div><pre class="code-pre yaml local-environment"><code langs="">- hosts: all
  become: yes
  tasks:
   - name: install Docker
     apt:
       name: docker.io
       state: present
       update_cache: true

   - name: install APT Transport HTTPS
     apt:
       name: apt-transport-https
       state: present

   - name: add Kubernetes apt-key
     apt_key:
       url: https://packages.cloud.google.com/apt/doc/apt-key.gpg
       state: present

   - name: add Kubernetes' APT repository
     apt_repository:
      repo: deb http://apt.kubernetes.io/ kubernetes-xenial main
      state: present
      filename: 'kubernetes'

   - name: install kubelet
     apt:
       name: kubelet=1.14.0-00
       state: present
       update_cache: true

   - name: install kubeadm
     apt:
       name: kubeadm=1.14.0-00
       state: present

- hosts: master
  become: yes
  tasks:
   - name: install kubectl
     apt:
       name: kubectl=1.14.0-00
       state: present
       force: yes
</code></pre>
<p>El primer play del playbook hace lo siguiente:</p>

<ul>
<li><p>Instala Docker, el tiempo de ejecución del contenedor.</p></li>
<li><p>Instala <code>apt-transport-https</code>, que le permite añadir fuentes HTTPS externas a su lista de fuentes APT.</p></li>
<li><p>Añade la clave apt del repositorio de APT de Kubernetes para la verificación de claves.</p></li>
<li><p>Añade el repositorio de APT de Kubernetes a la lista de fuentes APT de sus servidores remotos.</p></li>
<li><p>Instala <code>kubelet</code> y <code>kubeadm</code>.</p></li>
</ul>

<p>El segundo play consta de una única tarea que instala <code>kubectl</code> en su nodo maestro.</p>

<p><span class='note'><strong>Nota:</strong> Aunque en la documentación de Kubernetes se le recomienda usar la última versión estable de Kubernetes para su entorno, en este tutorial se utiliza una versión específica. Esto garantizará que pueda seguir los pasos correctamente, ya que Kubernetes cambia de forma rápida y es posible que la última versión no funcione con este tutorial.<br></span></p>

<p>Guarde y cierre el archivo cuando haya terminado.</p>

<p>A continuación, ejecute el playbook ejecutando lo siguiente a nivel local:</p>
<pre class="code-pre command local-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="$">ansible-playbook -i hosts ~/kube-cluster/kube-dependencies.yml
</li></ul></code></pre>
<p>Al finalizar, verá resultados similares al siguiente:</p>
<pre class="code-pre  local-environment"><code langs=""><div class="secondary-code-label " title="Output">Output</div>PLAY [all] ****

TASK [Gathering Facts] ****
ok: [worker1]
ok: [worker2]
ok: [master]

TASK [install Docker] ****
changed: [master]
changed: [worker1]
changed: [worker2]

TASK [install APT Transport HTTPS] *****
ok: [master]
ok: [worker1]
changed: [worker2]

TASK [add Kubernetes apt-key] *****
changed: [master]
changed: [worker1]
changed: [worker2]

TASK [add Kubernetes' APT repository] *****
changed: [master]
changed: [worker1]
changed: [worker2]

TASK [install kubelet] *****
changed: [master]
changed: [worker1]
changed: [worker2]

TASK [install kubeadm] *****
changed: [master]
changed: [worker1]
changed: [worker2]

PLAY [master] *****

TASK [Gathering Facts] *****
ok: [master]

TASK [install kubectl] ******
ok: [master]

PLAY RECAP ****
master                     : ok=9    changed=5    unreachable=0    failed=0   
worker1                    : ok=7    changed=5    unreachable=0    failed=0  
worker2                    : ok=7    changed=5    unreachable=0    failed=0  
</code></pre>
<p>Tras la ejecución, Docker, <code>kubeadm</code> y <code>kubelet</code> se instalarán en todos los servidores remotos. <code>kubectl</code> no es un componente necesario y solo se necesita para ejecutar comandos de clúster. Si la instalación se realiza solo en el nodo maestro tiene sentido en este contexto, ya que ejecutará comandos <code>kubectl</code> solo desde el maestro. Tenga en cuenta, sin embargo, que los comandos <code>kubectl</code> pueden ejecutarse desde cualquiera de los nodos de trabajo o desde cualquier máquina en donde se pueda instalar y configurar para apuntar a un clúster.</p>

<p>Con esto, quedarán instaladas todas las dependencias del sistema. Configuraremos el nodo maestro e iniciaremos el clúster.</p>

<h2 id="paso-4-configurar-el-nodo-maestro">Paso 4: Configurar el nodo maestro</h2>

<p>En esta sección, configurará el nodo maestro. Sin embargo, antes de crear cualquier playbook, valdrá la pena abarcar algunos conceptos como <em>Pods</em> y <em>complementos de red de Pods</em>, ya que su clúster incluirá ambos.</p>

<p>Un pod es una unidad atómica que ejecuta uno o más contenedores. Estos contenedores comparten recursos como volúmenes de archivos e interfaces de red en común. Los pods son la unidad básica de programación de Kubernetes: se garantiza que todos los contenedores de un pod se ejecutan en el mismo nodo en el que está programado el pod.</p>

<p>Cada pod tiene su propia dirección IP y un pod de un nodo debería poder acceder a un pod de otro usando el IP del pod. Los contenedores de un nodo único pueden comunicarse fácilmente a través de una interfaz local. Sin embargo, la comunicación entre los pods es más complicada y requiere un componente de red independiente que puede dirigir de forma transparente el tráfico de un pod de un nodo a un pod de otro.</p>

<p>Los complementos de red de pods ofrecen esta funcionalidad. Para este clúster usará <a href="https://github.com/coreos/flannel">Flannel</a>, una opción estable y apta.</p>

<p>Cree un libro de reproducción de Ansible llamado <code>master.yml</code> en su máquina local:</p>
<pre class="code-pre command local-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="$">nano ~/kube-cluster/master.yml
</li></ul></code></pre>
<p>Añada el siguiente play al archivo para iniciar el clúster e instalar Flannel:</p>
<div class="code-label " title="~/kube-cluster/master.yml">~/kube-cluster/master.yml</div><pre class="code-pre yaml local-environment"><code langs="">- hosts: master
  become: yes
  tasks:
    - name: initialize the cluster
      shell: kubeadm init --pod-network-cidr=10.244.0.0/16 &gt;&gt; cluster_initialized.txt
      args:
        chdir: $HOME
        creates: cluster_initialized.txt

    - name: create .kube directory
      become: yes
      become_user: ubuntu
      file:
        path: $HOME/.kube
        state: directory
        mode: 0755

    - name: copy admin.conf to user's kube config
      copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/ubuntu/.kube/config
        remote_src: yes
        owner: ubuntu

    - name: install Pod network
      become: yes
      become_user: ubuntu
      shell: kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml &gt;&gt; pod_network_setup.txt
      args:
        chdir: $HOME
        creates: pod_network_setup.txt
</code></pre>
<p>A continuación, se muestra un desglose de este play:</p>

<ul>
<li><p>La primera tarea inicia el clúster ejecutando <code>kubeadm init</code>. Pasar el argumento <code>--pod-network-cidr=10.244.0.0/16</code> especifica la subred privada desde la cual se asignarán los IP del pod. Flannel utiliza la subred anterior por defecto; le indicaremos a <code>kubeadm</code> que use la misma subred.</p></li>
<li><p>La segunda tarea crea un directorio <code>.kube</code> en <code>/home/ubuntu</code>. En este directorio se almacenarán datos de configuración, como los archivos de claves de administrador que se necesitan para establecer conexión con el clúster, y la dirección API del clúster.</p></li>
<li><p>La tercera tarea copia el archivo <code>/etc/kubernetes/admin.conf</code> que se generó desde <code>kubeadm init</code> al directorio principal de su usuario no root. Esto le permitirá usar <code>kubectl</code> para acceder al clúster recién creado.</p></li>
<li><p>La última tarea ejecuta <code>kubectl apply</code> para instalar <code>Flannel</code>. <code>kubectl apply -f descriptor.[yml|json]​​​​​​</code> es la sintaxis para indicar a ​​​<code>kubectl​​​​​​</code> que cree los objetos descritos en ​​​​​​el archivo <code>descriptor.[yml|json]​​​​​</code>. El archivo <code>kube-flannel.yml</code> contiene las descripciones de los objetos necesarios para configurar <code>Flannel</code> en el clúster.</p></li>
</ul>

<p>Guarde y cierre el archivo cuando haya terminado.</p>

<p>Implemente el playbook a nivel local ejecutando lo siguiente:</p>
<pre class="code-pre command local-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="$">ansible-playbook -i hosts ~/kube-cluster/master.yml
</li></ul></code></pre>
<p>Al finalizar, verá un resultado similar al siguiente:</p>
<pre class="code-pre  local-environment"><code langs=""><div class="secondary-code-label " title="Output">Output</div>
PLAY [master] ****

TASK [Gathering Facts] ****
ok: [master]

TASK [initialize the cluster] ****
changed: [master]

TASK [create .kube directory] ****
changed: [master]

TASK [copy admin.conf to user's kube config] *****
changed: [master]

TASK [install Pod network] *****
changed: [master]

PLAY RECAP ****
master                     : ok=5    changed=4    unreachable=0    failed=0  
</code></pre>
<p>Para comprobar el estado del nodo maestro, aplique SSH en él con el siguiente comando:</p>
<pre class="code-pre command local-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="$">ssh ubuntu@<span class="highlight">master_ip</span>
</li></ul></code></pre>
<p>Una vez dentro del nodo maestro, ejecute lo siguiente:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">kubectl get nodes
</li></ul></code></pre>
<p>Ahora verá lo siguiente:</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>NAME      STATUS    ROLES     AGE       VERSION
master    Ready     master    1d        v1.14.0
</code></pre>
<p>El resultado indica que el nodo <code>master</code> ha completado todas las tareas de inicialización y se encuentra en el estado <code>Ready</code>, a partir de lo cual puede comenzar a aceptar nodos de trabajo y ejecutar tareas enviadas al servidor de la API. Ahora puede añadir los trabajadores desde su máquina local.</p>

<h2 id="paso-5-configurar-los-nodos-del-trabajo">Paso 5: Configurar los nodos del trabajo</h2>

<p>La incorporación de trabajadores al clúster implica ejecutar un único comando en cada uno. Este comando incluye la información de clúster necesaria, como la dirección IP y el puerto del servidor de la API del maestro y un token seguro. Solo podrán incorporarse al clúster los nodos que puedan pasar el token seguro.</p>

<p>Regrese a su espacio de trabajo y cree un libro de reproducción denominado <code>workers.yml</code>:</p>
<pre class="code-pre command local-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="$">nano ~/kube-cluster/workers.yml
</li></ul></code></pre>
<p>Añada el siguiente texto al archivo para añadir los trabajadores al clúster:</p>
<div class="code-label " title="~/kube-cluster/workers.yml">~/kube-cluster/workers.yml</div><pre class="code-pre yaml local-environment"><code langs="">- hosts: master
  become: yes
  gather_facts: false
  tasks:
    - name: get join command
      shell: kubeadm token create --print-join-command
      register: join_command_raw

    - name: set join command
      set_fact:
        join_command: "{{ join_command_raw.stdout_lines[0] }}"


- hosts: workers
  become: yes
  tasks:
    - name: join cluster
      shell: "{{ hostvars['master'].join_command }} &gt;&gt; node_joined.txt"
      args:
        chdir: $HOME
        creates: node_joined.txt
</code></pre>
<p>Esto es lo que hace el playbook:</p>

<ul>
<li><p>El primer play obtiene el comando de incorporación que debe ejecutarse en los nodos de trabajo. Este comando se mostrará en el siguiente formato: <code>kubeadm join --token &lt;token&gt; &lt;master-ip&gt;:&lt;master-port&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt;</code> Una vez que obtiene el comando real con el <strong>token</strong> y los valores <strong>hash</strong> adecuados, la tarea lo establece como un hecho para que el siguiente play pueda acceder a esta información.</p></li>
<li><p>El segundo play tiene una sola tarea que ejecuta el comando de incorporación en todos los nodos de trabajo. Una vez que se complete esta tarea, los dos nodos de trabajo formarán parte del clúster.</p></li>
</ul>

<p>Guarde y cierre el archivo cuando haya terminado.</p>

<p>Implemente el playbook ejecutando lo siguiente a nivel local:</p>
<pre class="code-pre command local-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="$">ansible-playbook -i hosts ~/kube-cluster/workers.yml
</li></ul></code></pre>
<p>Al finalizar, verá resultados similares al siguiente:</p>
<pre class="code-pre  local-environment"><code langs=""><div class="secondary-code-label " title="Output">Output</div>PLAY [master] ****

TASK [get join command] ****
changed: [master]

TASK [set join command] *****
ok: [master]

PLAY [workers] *****

TASK [Gathering Facts] *****
ok: [worker1]
ok: [worker2]

TASK [join cluster] *****
changed: [worker1]
changed: [worker2]

PLAY RECAP *****
master                     : ok=2    changed=1    unreachable=0    failed=0   
worker1                    : ok=2    changed=1    unreachable=0    failed=0  
worker2                    : ok=2    changed=1    unreachable=0    failed=0  
</code></pre>
<p>Con la adición de los nodos de trabajo, ahora su clúster estará completamente configurado y activo, con los trabajadores listos para ejecutar el volumen de trabajo. Antes de programar aplicaciones, comprobaremos que el clúster funcione como se espera.</p>

<h2 id="paso-6-verificar-el-clúster">Paso 6: Verificar el clúster</h2>

<p>Un clúster puede fallar durante la configuración debido a la indisponibilidad de un nodo o a que la conexión de red entre el maestro y el trabajador no funciona correctamente. Comprobaremos el clúster y nos aseguraremos de que los nodos funcionen correctamente.</p>

<p>Deberá comprobar el estado actual del clúster desde el nodo maestro para asegurarse de que los nodos estén listos. Si interrumpió la conexión con el nodo maestro, puede aplicar SSH en él de nuevo con el siguiente comando:</p>
<pre class="code-pre command local-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="$">ssh ubuntu@<span class="highlight">master_ip</span>
</li></ul></code></pre>
<p>Luego, ejecute el siguiente comando para obtener el estado del clúster:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">kubectl get nodes
</li></ul></code></pre>
<p>El resultado debe ser similar a lo siguiente:</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>NAME      STATUS    ROLES     AGE       VERSION
master    Ready     master    1d        v1.14.0
worker1   Ready     &lt;none&gt;    1d        v1.14.0
worker2   Ready     &lt;none&gt;    1d        v1.14.0
</code></pre>
<p>Si el valor de <code>STATUS</code> es <code>Ready</code> para todos sus nodos, significa que son parte del clúster y están listos para ejecutar cargas de trabajo.</p>

<p>Sin embargo, si el valor de <code>STATUS</code> es <code>NotReady</code> para algunos de los nodos, podría significar que los nodos de trabajo aún no han terminado su configuración. Espere de 5 a 10 minutos antes de volver a ejecutar <code>kubectl get nodes</code> y verificar el nuevo resultado. Si el estado de algunos nodos todavía es <code>NotReady</code>, es posible que deba verificar y volver a ejecutar los comandos de los pasos anteriores.</p>

<p>Ahora que su clúster se ha verificado correctamente, programaremos una aplicación de Nginx de ejemplo en el clúster.</p>

<h2 id="paso-7-ejecutar-una-aplicación-en-el-clúster">Paso 7: Ejecutar una aplicación en el clúster</h2>

<p>Ahora puede implementar cualquier aplicación en contenedor en su clúster. Para que sea sencillo, implementaremos Nginx usando <em>implementaciones</em> y _servicios _para ver la forma en que se puede implementar esta aplicación en el clúster. Puede usar también los comandos que se muestran a continuación para otras aplicaciones en contenedores siempre que cambie el nombre de imagen de Docker y cualquier indicador pertinente (por ejemplo, <code>ports</code> y <code>volumes</code>).</p>

<p>Dentro del nodo maestro, ejecute el siguiente comando para crear una implementación llamada <code>nginx</code>:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">kubectl create deployment <span class="highlight">nginx</span> --image=<span class="highlight">nginx</span>
</li></ul></code></pre>
<p>Una implementación es un tipo de objeto de Kubernetes que garantiza que siempre haya un número especificado de pods ejecutándose según una plantilla definida, incluso cuando el pod se bloquee durante la vida útil del clúster. La implementación anterior creará un pod con un contenedor desde la <a href="https://hub.docker.com/_/nginx/">imagen de Docker de Nginx</a> del registro de Docker.</p>

<p>A continuación, ejecute el siguiente comando para crear un servicio llamado <code>nginx</code> que mostrará la aplicación públicamente. Esto lo hará a través de un <em>NodePort</em>, un esquema que permitirá el acceso al pod a través de un puerto arbitrario abierto en cada nodo del clúster:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">kubectl expose deploy <span class="highlight">nginx</span> --port <span class="highlight">80</span> --target-port <span class="highlight">80</span> --type NodePort
</li></ul></code></pre>
<p>Los servicios son otro tipo de objeto de Kubernetes que exponen los servicios internos del clúster a los clientes, tanto internos como externos. También pueden usar solicitudes de equilibrio de carga para varios pods y son un componente integral de Kubernetes que interactúa de forma frecuente con otros.</p>

<p>Ejecute el siguiente comando:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">kubectl get services
</li></ul></code></pre>
<p>Con esto se mostrará texto similar al siguiente:</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>NAME         TYPE        CLUSTER-IP       EXTERNAL-IP           PORT(S)             AGE
kubernetes   ClusterIP   10.96.0.1        &lt;none&gt;                443/TCP             1d
<span class="highlight">nginx</span>        NodePort    10.109.228.209   &lt;none&gt;                80:<span class="highlight">nginx_port</span>/TCP   40m
</code></pre>
<p>Desde la tercera línea del resultado anterior, puede recuperar el puerto en el que Nginx se ejecuta. Kubernetes asignará de forma aleatoria y automática un puerto superior al <code>30000</code>, y garantizará que no esté ya vinculado a otro servicio.</p>

<p>Para probar que todo esté funcionando, visite <code>http://<span class="highlight">worker_1_ip</span>:<span class="highlight">nginx_port</span></code> o <code>http://<span class="highlight">worker_2_ip</span>:<span class="highlight">nginx_port</span></code> a través de un navegador en su máquina local. Visualizará la página de bienvenida conocida de Nginx.</p>

<p>Si desea eliminar la aplicación de Nginx, primero elimine el servicio <code>nginx</code> del nodo maestro:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">kubectl delete service <span class="highlight">nginx</span>
</li></ul></code></pre>
<p>Ejecute lo siguiente para asegurarse de que el servicio se haya eliminado:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">kubectl get services
</li></ul></code></pre>
<p>Verá lo siguiente:</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>NAME         TYPE        CLUSTER-IP       EXTERNAL-IP           PORT(S)        AGE
kubernetes   ClusterIP   10.96.0.1        &lt;none&gt;                443/TCP        1d
</code></pre>
<p>Luego elimine la implementación:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">kubectl delete deployment <span class="highlight">nginx</span>
</li></ul></code></pre>
<p>Ejecute lo siguiente para confirmar que esto haya funcionado:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">kubectl get deployments
</li></ul></code></pre><pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>No resources found.
</code></pre>
<h2 id="conclusión">Conclusión</h2>

<p>A través de esta guía, configuró correctamente un clúster de Kubernetes en Ubuntu 18.04 usando Kubeadm y Ansible para la automatización.</p>

<p>Si se pregunta qué hacer con el clúster ahora que está configurado, un buen paso sería lograr implementar con comodidad aplicaciones y servicios propios en el clúster. A continuación, se presenta una lista de enlaces con más información que puede orientarlo en el proceso:</p>

<ul>
<li><p><a href="https://docs.docker.com/engine/examples/">Implementar Docker en aplicaciones</a>: contiene ejemplos en los que se detalla la forma de disponer aplicaciones en contenedores usando Docker.</p></li>
<li><p><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/">Descripción general de Pod:</a> describe en detalle el funcionaminento de los Pods y su relación con otros objetos Kubernetes. Los pods se encuentran en todas partes en Kubernetes. Por ello, si los comprende su trabajo será más sencillo.</p></li>
<li><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">Descripción general de las implementaciones</a>: ofrece un panorama de las implementaciones. Resulta útil comprender el funcionamiento de controladores como las implementaciones, ya que se utilizan con frecuencia en aplicaciones sin estado para escalar y reparar aplicaciones no saludables de forma automática.</p></li>
<li><p><a href="https://kubernetes.io/docs/concepts/services-networking/service/">Descripción general de services</a>: abarca services, otro objeto usado con frecuencia en los clústeres de Kubernetes. Comprender los tipos de servicios y las opciones que tienen es esencial para ejecutar aplicaciones con y sin estado.</p></li>
</ul>

<p>Otros conceptos importantes que puede ver son los de <a href="https://kubernetes.io/docs/concepts/storage/volumes/">Volume</a>, <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">Ingress</a> y <a href="https://kubernetes.io/docs/concepts/configuration/secret/">Secret</a>, los cuales son útiles cuando se implementan aplicaciones de producción.</p>

<p>Kubernetes ofrece muchas funciones y características. <a href="https://kubernetes.io/docs/">La documentación oficial de Kubernetes</a> es la mejor forma de aprender sobre conceptos, encontrar guías específicas para tareas y buscar referencias de API para varios objetos.</p>
