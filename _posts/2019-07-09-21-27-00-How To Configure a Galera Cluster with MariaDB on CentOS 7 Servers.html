---
layout: post
title: How To Configure a Galera Cluster with MariaDB on CentOS 7 Servers
network: digitalocean
date: July 09, 2019 at 09:27PM
---
<p><em>The author selected the <a href="https://www.brightfunds.org/funds/foss-nonprofits">Free and Open Source Fund</a> to receive a donation as part of the <a href="https://do.co/w4do-cta">Write for DOnations</a> program.</em></p>

<h3 id="introduction">Introduction</h3>

<p>Clustering adds high availability to your database by distributing changes to different servers. In the event that one of the instances fails, others are quickly available to continue serving. </p>

<p>Clusters come in two general configurations, <em>active-passive</em> and <em>active-active</em>. In active-passive clusters, all writes are done on a single active server and then copied to one or more passive servers that are poised to take over only in the event of an active server failure. Some active-passive clusters also allow <code>SELECT</code> operations on passive nodes. In an active-active cluster, every node is read-write and a change made to one is replicated to all.</p>

<p><a href="https://mariadb.org/">MariaDB</a> is an open source relational database system that is fully compatible with the popular MySQL RDBMS system. You can read the official documentation for MariaDB at this <a href="https://mariadb.com/kb/en/library/documentation/">page</a>. <a href="http://galeracluster.com/">Galera</a> is a database clustering solution that enables you to set up multi-master clusters using synchronous replication. Galera automatically handles keeping the data on different nodes in sync while allowing you to send read and write queries to any of the nodes in the cluster. You can learn more about Galera at the official <a href="http://galeracluster.com/library/documentation/">documentation page</a>.</p>

<p>In this guide, you will configure an active-active MariaDB Galera cluster. For demonstration purposes, you will configure and test three CentOS 7 Droplets that will act as nodes in the cluster. This is the smallest configurable cluster.</p>

<h2 id="prerequisites">Prerequisites</h2>

<p>To follow along, you will need a <a href="https://cloud.digitalocean.com/registrations/new">DigitalOcean account</a>, in addition to the following:</p>

<ul>
<li>Three CentOS 7 Droplets with private networking enabled, each with a non-root user with <code>sudo</code> privileges and a firewall enabled. 

<ul>
<li>For setting up private networking on the three Droplets, follow our <a href="https://www.digitalocean.com/docs/networking/private-networking/quickstart/">Private Networking Quickstart</a> guide.</li>
<li>For assistance setting up a non-root user with <code>sudo</code> privileges, follow our <a href="https://www.digitalocean.com/community/tutorials/initial-server-setup-with-centos-7">Initial Server Setup with CentOS 7</a> tutorial. To set up a firewall, check out the <strong>Configuring a Basic Firewall</strong> step of <a href="https://www.digitalocean.com/community/tutorials/additional-recommended-steps-for-new-centos-7-servers#configuring-a-basic-firewall">Additional Recommended Steps for New CentOS 7 Servers</a>.</li>
</ul></li>
</ul>

<p>While the steps in this tutorial have been written for and tested against DigitalOcean Droplets, many of them should also be applicable to non-DigitalOcean servers with private networking enabled.</p>

<h2 id="step-1-—-adding-the-mariadb-repositories-to-all-servers">Step 1 — Adding the MariaDB Repositories to All Servers</h2>

<p>In this step, you will add the relevant MariaDB package repositories to each of your three servers so that you will be able to install the right version of MariaDB used in this tutorial. Once the repositories are updated on all three servers, you will be ready to install MariaDB.</p>

<p>One thing to note about MariaDB is that it originated as a drop-in replacement for MySQL, so in many configuration files and startup scripts, you'll see <code>mysql</code> rather than <code>mariadb</code>. In many cases, these are interchangeable. For consistency's sake, we will use <code>mariadb</code> in this guide where either could work.</p>

<p>In this tutorial, you will use <a href="https://mariadb.com/kb/en/library/mariadb-1040-release-notes/">MariaDB version 10.4</a>. Since this version isn't included in the default CentOS repositories, you'll start by adding the external CentOS repository maintained by the MariaDB project to all three of your servers.</p>

<p><span class='note'><strong>Note:</strong>  MariaDB is a well-respected provider, but not all external repositories are reliable. Be sure to install only from trusted sources.<br></span></p>

<p>First, you'll add the MariaDB repository key by creating a repository file with a text editor. This tutorial will use <code>vi</code>:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo vi /etc/yum.repos.d/mariadb.repo
</li></ul></code></pre>
<p>Next, add the following contents to the file by pressing <code>i</code> to enter insert mode, then adding the following:</p>
<div class="code-label " title="/etc/yum.repos.d/mariadb.repo">/etc/yum.repos.d/mariadb.repo</div><pre class="code-pre "><code langs="">[mariadb]
name = MariaDB
baseurl = http://yum.mariadb.org/<span class="highlight">10.4</span>/centos7-amd64
gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB
gpgcheck=1
</code></pre>
<p>Press the <code>esc</code> key to return to normal mode, then type <code>:wq</code> to save and exit the file. If you would like to learn more about the text editor <code>vi</code> and its predecessor <code>vim</code>, take a look at our tutorial on <a href="https://www.digitalocean.com/community/tutorials/installing-and-using-the-vim-text-editor-on-a-cloud-server#modal-editing">Installing and Using the Vim Text Editor on a Cloud Server</a>.</p>

<p>Once you have created the repository file, enable it with the following command: </p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo yum makecache --disablerepo='*' --enablerepo='mariadb'
</li></ul></code></pre>
<p>The <code>makecache</code> command caches the repository metadata so that the package manager can install MariaDB, with <code>--disablerepo</code> and <code>--enablerepo</code> targeting the command to the <code>mariadb</code> repo file that you just created. </p>

<p>You will receive the following output:</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
mariadb                                                                                                                                                                              | 2.9 kB  00:00:00
(1/3): mariadb/primary_db                                                                                                                                                            |  43 kB  00:00:00
(2/3): mariadb/other_db                                                                                                                                                              | 8.3 kB  00:00:00
(3/3): mariadb/filelists_db                                                                                                                                                          | 238 kB  00:00:00
Metadata Cache Created
</code></pre>
<p>Once you have enabled the repository on your first server, repeat for your second and third servers.</p>

<p>Now that you have successfully added the package repository on all three of your servers, you're ready to install MariaDB in the next section.</p>

<h2 id="step-2-—-installing-mariadb-on-all-servers">Step 2 — Installing MariaDB on All Servers</h2>

<p>In this step, you will install the actual MariaDB packages on your three servers.</p>

<p>Beginning with version <code>10.1</code>, the MariaDB Server and MariaDB Galera Server packages are combined, so installing <code>MariaDB-server</code> will automatically install Galera and several dependencies:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo yum install MariaDB-server MariaDB-client
</li></ul></code></pre>
<p>You will be asked to confirm whether you would like to proceed with the installation. Enter <code>yes</code> to continue with the installation. You will then be prompted to accept the GPG key that authenticates the MariaDB package. Enter <code>yes</code> again.</p>

<p>When the installation is complete, start the <code>mariadb</code> service by running:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo systemctl start mariadb
</li></ul></code></pre>
<p>Enable the <code>mariadb</code> service to be automatically started on boot by executing:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo systemctl enable mariadb
</li></ul></code></pre>
<p>From MariaDB version <code>10.4</code> onwards, the <strong>root</strong> MariaDB user does not have a password by default. To set a password for the <strong>root</strong> user, start by logging into MariaDB:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo mysql -uroot
</li></ul></code></pre>
<p>Once you're inside the MariaDB shell, change the password by executing the following statement, replacing <code><span class="highlight">your_password</span></code> with your desired password:</p>
<pre class="code-pre custom_prefix"><code langs=""><ul class="prefixed"><li class="line" prefix="MariaDB[(none)]&gt;">set password = password("<span class="highlight">your_password</span>");
</li></ul></code></pre>
<p>You will see the following output indicating that the password was set correctly:</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>Query OK, 0 rows affected (0.001 sec)
</code></pre>
<p>Exit the MariaDB shell by running the following command:</p>
<pre class="code-pre custom_prefix"><code langs=""><ul class="prefixed"><li class="line" prefix="MariaDB[(none)]&gt;">quit;
</li></ul></code></pre>
<p>If you would like to learn more about SQL or need a quick refresher, check out our <a href="https://www.digitalocean.com/community/tutorials/a-basic-mysql-tutorial">MySQL tutorial</a>.</p>

<p>You now have all of the pieces necessary to begin configuring the cluster, but since you'll be relying on <code>rsync</code> and <code>policycoreutils-python</code> in later steps to sync the servers and to control Security-Enhanced Linux (SELinux), make sure they're installed before moving on:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo yum install rsync policycoreutils-python
</li></ul></code></pre>
<p>This will confirm that the newest versions of <code>rsync</code> and <code>policycoreutils-python</code> is already available or will prompt you to upgrade or install it.</p>

<p>Once you have completed these steps, repeat them for your other two servers.</p>

<p>Now that you have installed MariaDB successfully on each of the three servers, you can proceed to the configuration step in the next section.</p>

<h2 id="step-3-—-configuring-the-first-node">Step 3 — Configuring the First Node</h2>

<p>In this step you will configure your first Galera node. Each node in the cluster needs to have a nearly identical configuration. Because of this, you will do all of the configuration on your first machine, and then copy it to the other nodes.</p>

<p>By default, MariaDB is configured to check the <code>/etc/mysql/conf.d</code> directory to get additional configuration settings from files ending in <code>.cnf</code>. Create a file in this directory with all of your cluster-specific directives:</p>
<pre class="code-pre custom_prefix"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node01$">sudo vi /etc/my.cnf.d/galera.cnf
</li></ul></code></pre>
<p>Add the following configuration into the file. The configuration specifies different cluster options, details about the current server and the other servers in the cluster, and replication-related settings. Note that the IP addresses in the configuration are the private addresses of your respective servers; replace the highlighted lines with the appropriate IP addresses:</p>
<div class="code-label " title="/etc/my.cnf.d/galera.cnf">/etc/my.cnf.d/galera.cnf</div><pre class="code-pre "><code langs="">[mysqld]
binlog_format=ROW
default-storage-engine=innodb
innodb_autoinc_lock_mode=2
bind-address=0.0.0.0

# Galera Provider Configuration
wsrep_on=ON
wsrep_provider=/usr/lib64/galera-4/libgalera_smm.so

# Galera Cluster Configuration
wsrep_cluster_name="test_cluster"
wsrep_cluster_address="gcomm://<span class="highlight">First_Node_IP</span>,<span class="highlight">Second_Node_IP</span>,<span class="highlight">Third_Node_IP</span>"

# Galera Synchronization Configuration
wsrep_sst_method=rsync

# Galera Node Configuration
wsrep_node_address="<span class="highlight">This_Node_IP</span>"
wsrep_node_name="<span class="highlight">This_Node_Name</span>"
</code></pre>
<ul>
<li><strong>The first section</strong> modifies or re-asserts MariaDB/MySQL settings that will allow the cluster to function correctly. For example, Galera won’t work with MyISAM or similar non-transactional storage engines, and <code>mysqld</code> must not be bound to the IP address for <code>localhost</code>.</li>
<li><strong>The "Galera Provider Configuration" section</strong>  configures the MariaDB components that provide a WriteSet replication API. This means Galera in your case, since Galera is a <em>wsrep</em> (WriteSet Replication) provider. You specify the general parameters to configure the initial replication environment. This doesn't require any customization, but you can learn more about <a href="http://www.codership.com/wiki/doku.php?id=galera_parameters">Galera configuration options here</a>. </li>
<li><strong>The "Galera Cluster Configuration" section</strong> defines the cluster, identifying the cluster members by IP address or resolvable domain name and creating a name for the cluster to ensure that members join the correct group. You can change the <code>wsrep_cluster_name</code> to something more meaningful than <code>test_cluster</code> or leave it as-is, but you must update <code>wsrep_cluster_address</code> with the private IP addresses of your three servers.</li>
<li><strong>The "Galera Synchronization Configuration" section</strong> defines how the cluster will communicate and synchronize data between members. This is used only for the state transfer that happens when a node comes online. For your initial setup, you are using <code>rsync</code>, because it's commonly available and does what you'll need for now.</li>
<li><strong>The "Galera Node Configuration" section</strong> clarifies the IP address and the name of the current server. This is helpful when trying to diagnose problems in logs and for referencing each server in multiple ways. The <code>wsrep_node_address</code> must match the address of the machine you're on, but you can choose any name you want in order to help you identify the node in log files.</li>
</ul>

<p>When you are satisfied with your cluster configuration file, copy the contents into your clipboard and save and close the file.</p>

<p>Now that you have configured your first node successfully, you can move on to configuring the remaining nodes in the next section.</p>

<h2 id="step-4-—-configuring-the-remaining-nodes">Step 4 — Configuring the Remaining Nodes</h2>

<p>In this step, you will configure the remaining two nodes. On your second node, open the configuration file:</p>
<pre class="code-pre custom_prefix second-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-02$">sudo vi /etc/mysql/my.cnf.d/galera.cnf
</li></ul></code></pre>
<p>Paste in the configuration you copied from the first node, then update the <code>Galera Node Configuration</code> to use the IP address or resolvable domain name for the specific node you're setting up. Finally, update its name, which you can set to whatever helps you identify the node in your log files:</p>
<div class="code-label " title="/etc/mysql/my.cnf.d/galera.cnf">/etc/mysql/my.cnf.d/galera.cnf</div><pre class="code-pre "><code langs="">. . .
# Galera Node Configuration
wsrep_node_address="<span class="highlight">This_Node_IP</span>"
wsrep_node_name="<span class="highlight">This_Node_Name</span>"
. . .
</code></pre>
<p>Save and exit the file.</p>

<p>Once you have completed these steps, repeat them on the third node.</p>

<p>With Galera configured on all of your nodes, you're almost ready to bring up the cluster. But before you do, make sure that the appropriate ports are open in your firewall and that a SELinux policy has been created for Galera.</p>

<h2 id="step-5-—-opening-the-firewall-on-every-server">Step 5 — Opening the Firewall on Every Server</h2>

<p>In this step, you will configure your firewall so that the ports required for inter-node communication are open. </p>

<p>On every server, check the status of the firewall you set up in the Prerequisites section by running:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo firewall-cmd --list-all
</li></ul></code></pre>
<p>In this case, only SSH, DHCP, HTTP, and HTTPS traffic is allowed through:</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>public
  target: default
  icmp-block-inversion: no
  interfaces:
  sources:
  services: <span class="highlight">ssh dhcpv6-client http https</span>
  ports:
  protocols:
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:
</code></pre>
<p>If you tried to start the cluster now, it would fail because the firewall would block the connections between the nodes. To solve this problem, add rules to allow MariaDB and Galera traffic through. </p>

<p>Galera can make use of four ports:</p>

<ul>
<li><code>3306</code> For MariaDB client connections and State Snapshot Transfer that use the <code>mysqldump</code> method.</li>
<li><code>4567</code> For Galera Cluster replication traffic. Multicast replication uses both UDP transport and TCP on this port.</li>
<li><code>4568</code> For <em>Incremental State Transfers</em>, or IST, the process by which a missing state is received by other nodes in the cluster.</li>
<li><code>4444</code> For all other <em>State Snapshot Transfers</em>, or SST, the mechanism by which a joiner node gets its state and data from a donor node.</li>
</ul>

<p>In this example, you’ll open all four ports while you do your setup. Once you've confirmed that replication is working, you'd want to close any ports you're not actually using and restrict traffic to just servers in the cluster.</p>

<p>Open the ports with the following commands:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo firewall-cmd --permanent --zone=public --add-port=3306/tcp
</li><li class="line" prefix="$">sudo firewall-cmd --permanent --zone=public --add-port=4567/tcp
</li><li class="line" prefix="$">sudo firewall-cmd --permanent --zone=public --add-port=4568/tcp
</li><li class="line" prefix="$">sudo firewall-cmd --permanent --zone=public --add-port=4444/tcp
</li><li class="line" prefix="$">sudo firewall-cmd --permanent --zone=public --add-port=4567/udp
</li></ul></code></pre>
<p>Using <code>--zone=public</code> and <code>--add-port=</code> here, <code>firewall-cmd</code> is opening up these ports to public traffic. <code>--permanent</code> ensures that these rules persist.</p>

<p><span class='note'><strong>Note:</strong> Depending on what else is running on your servers you might want to restrict access right away. To learn more about how to use FirewallD, see our tutorial <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-using-firewalld-on-centos-7">How To Set Up a Firewall Using FirewallD on CentOS 7</a>.<br></span></p>

<p>Now, add each server to the <code>public</code> zone by executing the following commands, replacing the highlighted text with the respective private IP addresses of your nodes:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo firewall-cmd --permanent --zone=public --add-source=<span class="highlight">galera-node-1-ip</span>/32
</li><li class="line" prefix="$">sudo firewall-cmd --permanent --zone=public --add-source=<span class="highlight">galera-node-2-ip</span>/32
</li><li class="line" prefix="$">sudo firewall-cmd --permanent --zone=public --add-source=<span class="highlight">galera-node-3-ip</span>/32
</li></ul></code></pre>
<p>Reload the firewall to apply the changes:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo firewall-cmd --reload
</li></ul></code></pre>
<p>After you have configured your firewall on the first node, create the same firewall settings on the second and third node.</p>

<p>Now that you have configured the firewalls successfully, you're ready to create a SELinux policy in the next step.</p>

<h2 id="step-6-—-creating-a-selinux-policy">Step 6 — Creating a SELinux Policy</h2>

<p>In this section, you will create a SELinux policy that will allow all the nodes in the cluster to be able to communicate with each other and perform cluster operations.</p>

<p><a href="https://en.wikipedia.org/wiki/Security-Enhanced_Linux">SELinux</a> is a Linux kernel module that improves the security of operating systems with its support for access control and mandatory access control policies. It is enabled by default on CentOS 7 and restricts the MariaDB daemon from performing many activities.</p>

<p>In order to create the policy, you will perform various activities on the cluster with the SELinux mode set to permissive for MySQL. You will then create a policy from the logged events and finally set the SELinux mode to enforcing once the policy is installed successfully.</p>

<p>First, allow access to the relevant ports by running the following commands on all three servers:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo semanage port -a -t mysqld_port_t -p tcp 4567
</li><li class="line" prefix="$">sudo semanage port -a -t mysqld_port_t -p udp 4567
</li><li class="line" prefix="$">sudo semanage port -a -t mysqld_port_t -p tcp 4568
</li><li class="line" prefix="$">sudo semanage port -a -t mysqld_port_t -p tcp 4444
</li></ul></code></pre>
<p><span class='note'><strong>Note:</strong> You may receive a <code>ValueError</code> when allowing access to some of these ports. This means that the SELinux status of that port has already been set, which in this case will not affect the process of this tutorial.<br></span></p>

<p>In these commands, you are using the SELinux management tool <code>semanage</code> with the <code>-a</code> flag to add specified ports and to ignore the database server.</p>

<p>Next, run the following command on all three servers, which sets the MySQL SELinux domain to permissive mode temporarily.</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo semanage permissive -a mysqld_t
</li></ul></code></pre>
<p>This command can take a minute to complete and will not display any output.</p>

<p>Next, stop the database server on all the nodes so that you will be able to bootstrap the database cluster with shared SELinux policies. To do this, run the following command on all three nodes:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo systemctl stop mariadb
</li></ul></code></pre>
<p>Now, bootstrap the cluster to generate inter-node communication events that will be added to the SELinux policy. On the first node, bootstrap the cluster by executing:</p>
<pre class="code-pre custom_prefix"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-01$">sudo galera_new_cluster
</li></ul></code></pre>
<p>Create a database and table for the specific purpose of logging SST events by running the following on the first node:</p>
<pre class="code-pre custom_prefix"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-01$">mysql -u root -p -e 'CREATE DATABASE selinux;
</li><li class="line" prefix="galera-node-01$">CREATE TABLE selinux.selinux_policy (id INT NOT NULL AUTO_INCREMENT, PRIMARY KEY(id));
</li><li class="line" prefix="galera-node-01$">INSERT INTO selinux.selinux_policy VALUES ();'
</li></ul></code></pre>
<p>Now start the server on the second node:</p>
<pre class="code-pre custom_prefix second-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-02$">sudo systemctl start mariadb
</li></ul></code></pre>
<p>Then do the same on the third node:</p>
<pre class="code-pre custom_prefix third-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-03$">sudo systemctl start mariadb
</li></ul></code></pre>
<p>You will not see any output for the previous commands. To generate IST events, execute the following on all three servers:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">mysql -u root -p -e 'INSERT INTO selinux.selinux_policy VALUES ();'
</li></ul></code></pre>
<p>Now create and enable the SELinux policy by executing the following commands on all three servers:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo grep mysql /var/log/audit/audit.log | sudo audit2allow -M Galera
</li></ul></code></pre>
<p>This first command searches for generated events in the <code>audit.log</code> file and pipes them to a module named <code>Galera.pp</code> generated by the <code>audit2allow</code> tool. This will result in the following output:</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>******************** IMPORTANT ***********************
To make this policy package active, execute:

semodule -i Galera.pp

</code></pre>
<p>Next, follow the instructions in the output and use the following command to install the generated module:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo semodule -i Galera.pp
</li></ul></code></pre>
<p>Now that the policy is active, disable permissive mode for the MariaDB server:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo semanage permissive -d mysqld_t
</li></ul></code></pre>
<p>Now that you have successfully created a SELinux policy and enabled it, you are ready to start the cluster in the next section.</p>

<h2 id="step-7-—-starting-the-cluster">Step 7 — Starting the Cluster</h2>

<p>In this step, you will start your MariaDB cluster. To begin, you need to stop the running MariaDB service so that you can bring your cluster online.</p>

<h3 id="stop-mariadb-on-all-three-servers">Stop MariaDB on All Three Servers</h3>

<p>When stopping the MariaDB service, it is important to execute this action on your servers in a specific order. This shutdown sequence ensures that the first node will be able to safely bootstrap the cluster when it starts up.</p>

<p>First, run the following command on the third node:</p>
<pre class="code-pre custom_prefix third-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-03$">sudo systemctl stop mariadb
</li></ul></code></pre>
<p>Next, stop the service on the second node:</p>
<pre class="code-pre custom_prefix second-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-02$">sudo systemctl stop mariadb
</li></ul></code></pre>
<p>Finally, stop the service on the first node:</p>
<pre class="code-pre custom_prefix"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-01$">sudo systemctl stop mariadb
</li></ul></code></pre>
<p><code>systemctl</code> doesn't display the outcome of all service management commands, so to be sure you succeeded, use the following command on each of your servers:  </p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo systemctl status mariadb
</li></ul></code></pre>
<p>The last line will look something like the following:</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>. . . 
Apr 26 03:34:23 galera-node-01 systemd[1]: Stopped MariaDB 10.4.4 database server.
</code></pre>
<p>Once you've shut down <code>mariadb</code> on all of the servers, you're ready to proceed.</p>

<h3 id="bring-up-the-first-node">Bring Up the First Node</h3>

<p>To bring up the first node, you'll need to use a special startup script. The way you've configured your cluster, each node that comes online tries to connect to at least one other node specified in its <code>galera.cnf</code> file to get its initial state. Without using the <code>galera_new_cluster</code> script that allows systemd to pass the <code>--wsrep-new-cluster</code> parameter,  a normal <code>systemctl start mariadb</code> would fail because there are no nodes running for the first node to connect with.</p>
<pre class="code-pre custom_prefix"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-01$">sudo galera_new_cluster
</li></ul></code></pre>
<p>This command will not display any output on successful execution. When this script succeeds, the node is registered as part of the cluster, and you can see it with the following command:</p>
<pre class="code-pre custom_prefix"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-01$">mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size'"
</li></ul></code></pre>
<p>You will see the following output indicating that there is one node in the cluster:</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 1     |
+--------------------+-------+
</code></pre>
<p>On the remaining nodes, you can start <code>mariadb</code> normally. They will search for any member of the cluster list that is online, so when they find one, they will join the cluster.</p>

<h3 id="bring-up-the-second-node">Bring Up the Second Node</h3>

<p>Now you can bring up the second node. Start <code>mariadb</code>:</p>
<pre class="code-pre custom_prefix second-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-02$">sudo systemctl start mariadb
</li></ul></code></pre>
<p>No output will be displayed on successful execution. You will see your cluster size increase as each node comes online:</p>
<pre class="code-pre custom_prefix second-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-02$">mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size'"
</li></ul></code></pre>
<p>You will see the following output indicating that the second node has joined the cluster and that there are two nodes in total.</p>
<pre class="code-pre  second-environment"><code langs=""><div class="secondary-code-label " title="Output">Output</div>+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 2     |
+--------------------+-------+
</code></pre>
<h3 id="bring-up-the-third-node">Bring Up the Third Node</h3>

<p>It's now time to bring up the third node. Start <code>mariadb</code>:</p>
<pre class="code-pre custom_prefix third-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-03$">sudo systemctl start mariadb
</li></ul></code></pre>
<p>Run the following command to find the cluster size:</p>
<pre class="code-pre custom_prefix third-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-03$">mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size'"
</li></ul></code></pre>
<p>You will see the following output, which indicates that the third node has joined the cluster and that the total number of nodes in the cluster is three.</p>
<pre class="code-pre  third-environment"><code langs=""><div class="secondary-code-label " title="Output">Output</div>+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 3     |
+--------------------+-------+
</code></pre>
<p>At this point, the entire cluster is online and communicating successfully. Next, you can ensure the working setup by testing replication in the next section.</p>

<h2 id="step-8-—-testing-replication">Step 8 — Testing Replication</h2>

<p>You've gone through the steps up to this point so that your cluster can perform replication from any node to any other node, known as active-active replication. Follow the following steps to test and see if the replication is working as expected.</p>

<h3 id="write-to-the-first-node">Write to the First Node</h3>

<p>You'll start by making database changes on your first node. The following commands will create a database called <code>playground</code> and a table inside of this database called <code>equipment</code>.</p>
<pre class="code-pre custom_prefix"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-01$">mysql -u root -p -e 'CREATE DATABASE playground;
</li><li class="line" prefix="galera-node-01$">CREATE TABLE playground.equipment ( id INT NOT NULL AUTO_INCREMENT, type VARCHAR(50), quant INT, color VARCHAR(25), PRIMARY KEY(id));
</li><li class="line" prefix="galera-node-01$">INSERT INTO playground.equipment (type, quant, color) VALUES ("slide", 2, "blue");'
</li></ul></code></pre>
<p>In the previous command, the <code>CREATE DATABASE</code> statement creates a database named <code>playground</code>. The <code>CREATE</code> statement creates a table named <code>equipment</code> inside the <code>playground</code> database having an auto-incrementing identifier column called <code>id</code> and other columns. The <code>type</code> column, <code>quant</code> column, and <code>color</code> column are defined to store the type, quantity, and color of the equipment respectively. The <code>INSERT</code> statement inserts an entry of type <code>slide</code>, quantity <code>2</code>, and color <code>blue</code>.</p>

<p>You now have one value in your table.</p>

<h3 id="read-and-write-on-the-second-node">Read and Write on the Second Node</h3>

<p>Next, look at the second node to verify that replication is working:</p>
<pre class="code-pre custom_prefix second-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-02$">mysql -u root -p -e 'SELECT * FROM playground.equipment;'
</li></ul></code></pre>
<p>If replication is working, the data you entered on the first node will be visible here on the second:</p>
<pre class="code-pre  second-environment"><code langs=""><div class="secondary-code-label " title="Output">Output</div>+----+-------+-------+-------+
| id | type  | quant | color |
+----+-------+-------+-------+
|  1 | slide |     2 | blue  |
+----+-------+-------+-------+
</code></pre>
<p>From this same node, you can write data to the cluster:</p>
<pre class="code-pre custom_prefix second-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-02$">mysql -u root -p -e 'INSERT INTO playground.equipment (type, quant, color) VALUES ("swing", 10, "yellow");'
</li></ul></code></pre>
<h3 id="read-and-write-on-the-third-node">Read and Write on the Third Node</h3>

<p>From the third node, you can read all of this data by querying the table again:</p>
<pre class="code-pre custom_prefix third-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-03$">mysql -u root -p -e 'SELECT * FROM playground.equipment;'
</li></ul></code></pre>
<p>You will see the following output showing the two rows:</p>
<pre class="code-pre  third-environment"><code langs=""><div class="secondary-code-label " title="Output">Output</div>   +----+-------+-------+--------+
   | id | type  | quant | color  |
   +----+-------+-------+--------+
   |  1 | slide |     2 | blue   |
   |  2 | swing |    10 | yellow |
   +----+-------+-------+--------+
</code></pre>
<p>Again, you can add another value from this node:</p>
<pre class="code-pre custom_prefix third-environment"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-03$">mysql -u root -p -e 'INSERT INTO playground.equipment (type, quant, color) VALUES ("seesaw", 3, "green");'
</li></ul></code></pre>
<h3 id="read-on-the-first-node">Read on the First Node</h3>

<p>Back on the first node, you can verify that your data is available everywhere:</p>
<pre class="code-pre custom_prefix"><code langs=""><ul class="prefixed"><li class="line" prefix="galera-node-01$">mysql -u root -p -e 'SELECT * FROM playground.equipment;'
</li></ul></code></pre>
<p>You will see the following output, which indicates that the rows are available on the first node.</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>   +----+--------+-------+--------+
   | id | type   | quant | color  |
   +----+--------+-------+--------+
   |  1 | slide  |     2 | blue   |
   |  2 | swing  |    10 | yellow |
   |  3 | seesaw |     3 | green  |
   +----+--------+-------+--------+
</code></pre>
<p>You've verified successfully that you can write to all of the nodes and that replication is being performed properly.</p>

<h2 id="conclusion">Conclusion</h2>

<p>At this point, you have a working three-node Galera test cluster configured. If you plan on using a Galera cluster in a production situation, it’s recommended that you begin with no fewer than five nodes.</p>

<p>Before production use, you may want to take a look at some of the <a href="http://galeracluster.com/documentation-webpages/sst.html">other state snapshot transfer (SST) agents</a> like <strong>XtraBackup</strong>, which allows you to set up new nodes very quickly and without large interruptions to your active nodes. This does not affect the actual replication, but is a concern when nodes are being initialized.</p>

<p>If you would like to continue learning about SQL databases, take a look at our <a href="https://www.digitalocean.com/community/tutorials/how-to-manage-sql-database-cheat-sheet">How To Manage an SQL Database</a> article.</p>

url: https://www.digitalocean.com/community/tutorials/how-to-configure-a-galera-cluster-with-mariadb-on-centos-7-servers
image: http://ifttt.com/images/no_image_card.png
tags: docker
feedtitle: DigitalOcean Community Tutorials
feedurl: https://www.digitalocean.com/community/tutorials
author: DigitalOcean