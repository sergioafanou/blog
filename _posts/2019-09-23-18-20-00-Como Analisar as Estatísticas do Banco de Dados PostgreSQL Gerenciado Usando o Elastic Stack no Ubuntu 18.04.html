---
layout: post
title: Como Analisar as Estatísticas do Banco de Dados PostgreSQL Gerenciado Usando o Elastic Stack no Ubuntu 18.04
network: digitalocean
date: September 23, 2019 at 06:20PM
url: https://www.digitalocean.com/community/tutorials/como-analisar-as-estatisticas-do-banco-de-dados-postgresql-gerenciado-usando-o-elastic-stack-no-ubuntu-18-04-pt
image: https://assets.digitalocean.com/articles/postgres_managed_elk/step4a.png
tags: docker
feedtitle: DigitalOcean Community Tutorials
feedurl: https://www.digitalocean.com/community/tutorials
author: DigitalOcean
---
<p><em>O autor escolheu o <a href="https://www.brightfunds.org/funds/foss-nonprofits">Free and Open Source Fund</a> para receber uma doação como parte do programa <a href="https://do.co/w4do-cta">Write for DOnations</a>.</em></p>

<h3 id="introdução">Introdução</h3>

<p>O monitoramento de banco de dados é o processo contínuo de rastrear sistematicamente várias métricas que mostram como o banco de dados está se comportando. Ao observar os dados de desempenho, você pode obter informações valiosas e identificar possíveis gargalos, além de encontrar maneiras adicionais de melhorar o desempenho do banco de dados. Esses sistemas geralmente implementam alertas que notificam os administradores quando as coisas dão errado. As estatísticas coletadas podem ser usadas não apenas para melhorar a configuração e o fluxo de trabalho do banco de dados, mas também para os aplicativos clientes.</p>

<p>Os benefícios da utilização do <a href="https://www.elastic.co/products/elastic-stack">Elastic Stack</a> (ELK stack) para monitorar seu banco de dados gerenciado, é seu excelente suporte para pesquisa e a capacidade de ingerir novos dados muito rapidamente. Ele não se destaca na atualização dos dados, mas esse trade-off é aceitável para fins de monitoramento e logs, onde dados passados quase nunca são alterados. O <a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a> oferece meios poderosos de consultar os dados, que você pode usar através do <a href="https://www.elastic.co/products/kibana">Kibana</a> para entender melhor como o banco de dados se sai em diferentes períodos de tempo. Isso permitirá que você correlacione a carga do banco de dados com eventos da vida real para obter informações sobre como o banco de dados está sendo usado.</p>

<p>Neste tutorial, você importará métricas de banco de dados geradas pelo <a href="https://www.postgresql.org/docs/9.6/monitoring-stats.html">coletor de estatísticas do PostgreSQL</a> no Elasticsearch via <a href="https://www.elastic.co/products/logstash">Logstash</a>. Isso implica em configurar o Logstash para extrair dados do banco de dados usando o <a href="https://jdbc.postgresql.org/">conector JDBC do PostgreSQL</a> para enviá-los ao Elasticsearch para indexação imediatamente após. Os dados importados podem ser analisados e visualizados posteriormente no Kibana. Então, se seu banco de dados for novo, você usará o <a href="https://www.postgresql.org/docs/11/pgbench.html">pgbench</a>, uma ferramenta de benchmarking do PostgreSQL, para criar visualizações mais interessantes. No final, você terá um sistema automatizado buscando as estatísticas do PostgreSQL para análise posterior.</p>

<h2 id="pré-requisitos">Pré-requisitos</h2>

<ul>
<li><p>Um servidor Ubuntu 18.04 com pelo menos 4 GB de RAM, privilégios de root, e uma conta secundária não-root. Você pode configurar isso seguindo este <a href="https://www.digitalocean.com/community/tutorials/configuracao-inicial-de-servidor-com-ubuntu-18-04-pt">guia de Configuração Inicial de servidor com Ubuntu 18.04</a>. Para este tutorial o usuário não-root é o <code><span class="highlight">sammy</span></code>.</p></li>
<li><p>Java 8 instalado em seu servidor. Para instruções de instalação, visite <a href="https://www.digitalocean.com/community/tutorials/como-instalar-o-java-com-apt-no-ubuntu-18-04-pt">Como Instalar o Java com <code>apt</code> no Ubuntu 18.04</a>.</p></li>
<li><p>Nginx instalado em seu servidor. Para um guia sobre como fazer isso, consulte <a href="https://www.digitalocean.com/community/tutorials/como-instalar-o-nginx-no-ubuntu-18-04-pt">Como Instalar o Nginx no Ubuntu 18.04</a>.</p></li>
<li><p>Elasticsearch e Kibana instalados em seu servidor. Conclua os dois primeiros passos do tutorial <a href="https://www.digitalocean.com/community/tutorials/como-instalar-elasticsearch-logstash-e-kibana-elastic-stack-no-ubuntu-18-04-pt">Como Instalar Elasticsearch, Logstash e Kibana (Elastic Stack) no Ubuntu 18.04</a></p></li>
<li><p>Um banco de dados PostgreSQL gerenciado provisionado a partir da DigitalOcean com informações de conexão disponíveis. Verifique se o endereço IP do seu servidor está na lista permitida ou whitelist. Para saber mais sobre os bancos de dados gerenciados da DigitalOcean, visite a <a href="https://www.digitalocean.com/docs/databases/overview/">documentação de produto</a>.</p></li>
</ul>

<h2 id="passo-1-—-configurando-o-logstash-e-o-driver-jdbc-para-postgresql">Passo 1 — Configurando o Logstash e o Driver JDBC para PostgreSQL</h2>

<p>Nesta seção, você instalará o Logstash e fará o download do <a href="https://jdbc.postgresql.org/index.html">driver JDBC para PostgreSQL</a> para que o Logstash possa se conectar ao seu banco de dados gerenciado.</p>

<p>Comece instalando o Logstash com o seguinte comando:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo apt install logstash -y
</li></ul></code></pre>
<p>Depois que o Logstash estiver instalado, habilite o serviço para iniciar automaticamente na inicialização:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo systemctl enable logstash
</li></ul></code></pre>
<p>O Logstash é escrito em Java, portanto, para conectar-se ao PostgreSQL, é necessário que a biblioteca JDBC (Java Database Connectivity) do PostgreSQL esteja disponível no sistema em que está sendo executado. Por causa de uma limitação interna, o Logstash carregará adequadamente a biblioteca apenas se for encontrada no diretório <code>/usr/share/logstash/logstash-core/lib/jars</code>, onde armazena bibliotecas de terceiros que ele utiliza.</p>

<p>Vá para a <a href="https://jdbc.postgresql.org/download.html#current">página de download</a> da biblioteca JDBC e copie o link para a versão mais recente. Em seguida, faça o download usando <code>curl</code> executando o seguinte comando: </p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo curl https://jdbc.postgresql.org/download/postgresql-<span class="highlight">42.2.6</span>.jar -o /usr/share/logstash/logstash-core/lib/jars/postgresql-jdbc.jar
</li></ul></code></pre>
<p>No momento da escrita deste tutorial, a versão mais recente da biblioteca era a <code><span class="highlight">42.2.6</span></code>, com o Java 8 como a versão runtime suportada. Certifique-se de baixar a versão mais recente; emparelhando-a com a versão Java correta que tanto o JDBC quanto o Logstash suportam.</p>

<p>O Logstash armazena seus arquivos de configuração em <code>/etc/logstash/conf.d</code> e armazena a si próprio em <code>/usr/share/logstash/bin</code>. Antes de criar uma configuração que coletará estatísticas do seu banco de dados, será necessário ativar o plug-in JDBC no Logstash executando o seguinte comando:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo /usr/share/logstash/bin/logstash-plugin install logstash-input-jdbc
</li></ul></code></pre>
<p>Você instalou o Logstash usando o <code>apt</code> e baixou a biblioteca JDBC do PostgreSQL para que o Logstash possa usá-la para conectar-se ao seu banco de dados gerenciado. Na próximo passo, você configurará o Logstash para coletar dados estatísticos dele.</p>

<h2 id="passo-2-—-configurando-o-logstash-para-coletar-estatísticas">Passo 2 — Configurando o Logstash Para Coletar Estatísticas</h2>

<p>Nesta seção, você configurará o Logstash para coletar métricas do seu banco de dados PostgreSQL gerenciado.</p>

<p>Você configurará o Logstash para monitorar três bancos de dados de sistema no PostgreSQL, a saber:</p>

<ul>
<li><code>pg_stat_database</code>: fornece estatísticas sobre cada banco de dados, incluindo seu nome, número de conexões, transações, rollbacks, linhas retornadas ao consultar o banco de dados, deadlocks e assim por diante. Possui um campo <code>stats_reset</code>, que especifica quando as estatísticas foram zeradas pela última vez.</li>
<li><code>pg_stat_user_tables</code>: fornece estatísticas sobre cada tabela criada pelo usuário, como o número de linhas inseridas, excluídas e atualizadas.</li>
<li><code>pg_stat_user_indexes</code>: coleta dados sobre todos os índices em tabelas criadas pelo usuário, como o número de vezes que um índice específico foi consultado.</li>
</ul>

<p>Você armazenará a configuração para indexar as estatísticas do PostgreSQL no Elasticsearch em um arquivo chamado <code>postgresql.conf</code> no diretório <code>/etc/logstash/conf.d</code>, onde o Logstash armazena arquivos de configuração. Quando iniciado como um serviço, ele será executado automaticamente em segundo plano.</p>

<p>Crie o <code>postgresql.conf</code> usando seu editor de textos favorito (por exemplo, o nano):</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo nano /etc/logstash/conf.d/postgresql.conf
</li></ul></code></pre>
<p>Adicione as seguintes linhas:</p>
<div class="code-label " title="/etc/logstash/conf.d/postgresql.conf">/etc/logstash/conf.d/postgresql.conf</div><pre class="code-pre "><code langs="">input {
        # pg_stat_database
        jdbc {
                jdbc_driver_library =&gt; ""
                jdbc_driver_class =&gt; "org.postgresql.Driver"
                jdbc_connection_string =&gt; "jdbc:postgresql://<span class="highlight">host</span>:<span class="highlight">port</span>/defaultdb"
                jdbc_user =&gt; "<span class="highlight">username</span>"
                jdbc_password =&gt; "<span class="highlight">password</span>"
                statement =&gt; "SELECT * FROM pg_stat_database"
                schedule =&gt; "* * * * *"
                type =&gt; "pg_stat_database"
        }

        # pg_stat_user_tables
        jdbc {
                jdbc_driver_library =&gt; ""
                jdbc_driver_class =&gt; "org.postgresql.Driver"
                jdbc_connection_string =&gt; "jdbc:postgresql://<span class="highlight">host</span>:<span class="highlight">port</span>/defaultdb"
                jdbc_user =&gt; "<span class="highlight">username</span>"
                jdbc_password =&gt; "<span class="highlight">password</span>"
                statement =&gt; "SELECT * FROM pg_stat_user_tables"
                schedule =&gt; "* * * * *"
                type =&gt; "pg_stat_user_tables"
        }

        # pg_stat_user_indexes
        jdbc {
                jdbc_driver_library =&gt; ""
                jdbc_driver_class =&gt; "org.postgresql.Driver"
                jdbc_connection_string =&gt; "jdbc:postgresql://<span class="highlight">host</span>:<span class="highlight">port</span>/defaultdb"
                jdbc_user =&gt; "<span class="highlight">username</span>"
                jdbc_password =&gt; "<span class="highlight">password</span>"
                statement =&gt; "SELECT * FROM pg_stat_user_indexes"
                schedule =&gt; "* * * * *"
                type =&gt; "pg_stat_user_indexes"
        }
}

output {
        elasticsearch {
                hosts =&gt; "http://localhost:9200"
                index =&gt; "%{type}"
        }
}
</code></pre>
<p>Lembre-se de substituir <code><span class="highlight">host</span></code> pelo seu endereço de host, <code><span class="highlight">port</span></code> pela porta à qual você pode se conectar ao seu banco de dados, <code><span class="highlight">username</span></code> pelo nome de usuário do banco de dados e <code><span class="highlight">password</span></code> pela sua senha. Todos esses valores podem ser encontrados no Painel de Controle do seu banco de dados gerenciado.</p>

<p>Nesta configuração, você define três entradas JDBC e uma saída Elasticsearch. As três entradas extraem dados dos bancos de dados <code>pg_stat_database</code>, <code>pg_stat_user_tables</code> e <code>pg_stat_user_indexes</code>, respectivamente. Todos eles definem o parâmetro <code>jdbc_driver_library</code> como uma string vazia, porque a biblioteca JDBC do PostgreSQL está em uma pasta que o Logstash carrega automaticamente.</p>

<p>Em seguida, eles definem o <code>jdbc_driver_class</code>, cujo valor é específico da biblioteca JDBC, e fornecem uma <code>jdbc_connection_string</code>, que detalha como se conectar ao banco de dados. A parte <code>jdbc:</code> significa que é uma conexão JDBC, enquanto <code>postgres://</code> indica que o banco de dados de destino é o PostgreSQL. Em seguida, vem o host e a porta do banco de dados e, após a barra, você também especifica um banco de dados ao qual se conectar; isso ocorre porque o PostgreSQL exige que você esteja conectado a um banco de dados para poder emitir quaisquer consultas. Aqui, ele está definido como o banco de dados padrão que sempre existe e não pode ser excluído, apropriadamente denominado de <code>defaultdb</code>.</p>

<p>Em seguida, eles definem um nome de usuário e a senha do usuário através do qual o banco de dados será acessado. O parâmetro <code>statement</code> contém uma consulta SQL que deve retornar os dados que você deseja processar — nessa configuração, ele seleciona todas as linhas do banco de dados apropriado.</p>

<p>O parâmetro <code>schedule</code> aceita uma string na sintaxe do <a href="https://en.wikipedia.org/wiki/Cron">cron</a> que define quando o Logstash deve executar esta entrada; omiti-lo completamente fará com que o Logstash a execute apenas uma vez. Especificando <code>* * * * *</code>, como você fez aqui, dirá ao Logstash para executá-la a cada minuto. Você pode especificar sua própria string do cron se desejar coletar dados em diferentes intervalos. </p>

<p>Há apenas uma saída, que aceita dados de três entradas. Todas elas enviam dados para o Elasticsearch, que está sendo executado localmente e pode ser acessado em <code>http://localhost:9200</code>. O parâmetro <code>index</code> define para qual índice do Elasticsearch ele enviará os dados e seu valor é passado no campo <code>type</code> da entrada.</p>

<p>Quando você terminar de editar, salve e feche o arquivo.</p>

<p>Você configurou o Logstash para reunir dados de várias tabelas estatísticas do PostgreSQL e enviá-los ao Elasticsearch para armazenamento e indexação. Em seguida, você executará o Logstash para testar a configuração.</p>

<h2 id="passo-3-—-testando-a-configuração-do-logstash">Passo 3 — Testando a Configuração do Logstash</h2>

<p>Nesta seção, você testará a configuração executando o Logstash para verificar se ele extrairá os dados corretamente. Em seguida, você executará essa configuração em segundo plano, configurando-a como um pipeline do Logstash.</p>

<p>O Logstash suporta a execução de uma configuração específica, passando seu caminho de arquivo para o parâmetro <code>-f</code>. Execute o seguinte comando para testar sua nova configuração da último passo:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/postgresql.conf
</li></ul></code></pre>
<p>Pode levar algum tempo até que ele mostre qualquer saída, que será semelhante a esta:</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>Thread.exclusive is deprecated, use Thread::Mutex
WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaults
Could not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the console
[WARN ] 2019-08-02 18:29:15.123 [LogStash::Runner] multilocal - Ignoring the 'pipelines.yml' file because modules or command line options are specified
[INFO ] 2019-08-02 18:29:15.154 [LogStash::Runner] runner - Starting Logstash {"logstash.version"=&gt;"7.3.0"}
[INFO ] 2019-08-02 18:29:18.209 [Converge PipelineAction::Create&lt;main&gt;] Reflections - Reflections took 77 ms to scan 1 urls, producing 19 keys and 39 values
[INFO ] 2019-08-02 18:29:20.195 [[main]-pipeline-manager] elasticsearch - Elasticsearch pool URLs updated {:changes=&gt;{:removed=&gt;[], :added=&gt;[http://localhost:9200/]}}
[WARN ] 2019-08-02 18:29:20.667 [[main]-pipeline-manager] elasticsearch - Restored connection to ES instance {:url=&gt;"http://localhost:9200/"}
[INFO ] 2019-08-02 18:29:21.221 [[main]-pipeline-manager] elasticsearch - ES Output version determined {:es_version=&gt;7}
[WARN ] 2019-08-02 18:29:21.230 [[main]-pipeline-manager] elasticsearch - Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=&gt;7}
[INFO ] 2019-08-02 18:29:21.274 [[main]-pipeline-manager] elasticsearch - New Elasticsearch output {:class=&gt;"LogStash::Outputs::ElasticSearch", :hosts=&gt;["http://localhost:9200"]}
[INFO ] 2019-08-02 18:29:21.337 [[main]-pipeline-manager] elasticsearch - Elasticsearch pool URLs updated {:changes=&gt;{:removed=&gt;[], :added=&gt;[http://localhost:9200/]}}
[WARN ] 2019-08-02 18:29:21.369 [[main]-pipeline-manager] elasticsearch - Restored connection to ES instance {:url=&gt;"http://localhost:9200/"}
[INFO ] 2019-08-02 18:29:21.386 [[main]-pipeline-manager] elasticsearch - ES Output version determined {:es_version=&gt;7}
[WARN ] 2019-08-02 18:29:21.386 [[main]-pipeline-manager] elasticsearch - Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=&gt;7}
[INFO ] 2019-08-02 18:29:21.409 [[main]-pipeline-manager] elasticsearch - New Elasticsearch output {:class=&gt;"LogStash::Outputs::ElasticSearch", :hosts=&gt;["http://localhost:9200"]}
[INFO ] 2019-08-02 18:29:21.430 [[main]-pipeline-manager] elasticsearch - Elasticsearch pool URLs updated {:changes=&gt;{:removed=&gt;[], :added=&gt;[http://localhost:9200/]}}
[WARN ] 2019-08-02 18:29:21.444 [[main]-pipeline-manager] elasticsearch - Restored connection to ES instance {:url=&gt;"http://localhost:9200/"}
[INFO ] 2019-08-02 18:29:21.465 [[main]-pipeline-manager] elasticsearch - ES Output version determined {:es_version=&gt;7}
[WARN ] 2019-08-02 18:29:21.466 [[main]-pipeline-manager] elasticsearch - Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=&gt;7}
[INFO ] 2019-08-02 18:29:21.468 [Ruby-0-Thread-7: :1] elasticsearch - Using default mapping template
[INFO ] 2019-08-02 18:29:21.538 [Ruby-0-Thread-5: :1] elasticsearch - Using default mapping template
[INFO ] 2019-08-02 18:29:21.545 [[main]-pipeline-manager] elasticsearch - New Elasticsearch output {:class=&gt;"LogStash::Outputs::ElasticSearch", :hosts=&gt;["http://localhost:9200"]}
[INFO ] 2019-08-02 18:29:21.589 [Ruby-0-Thread-9: :1] elasticsearch - Using default mapping template
[INFO ] 2019-08-02 18:29:21.696 [Ruby-0-Thread-5: :1] elasticsearch - Attempting to install template {:manage_template=&gt;{"index_patterns"=&gt;"logstash-*", "version"=&gt;60001, "settings"=&gt;{"index.refresh_interval"=&gt;"5s", "number_of_shards"=&gt;1}, "mappings"=&gt;{"dynamic_templates"=&gt;[{"message_field"=&gt;{"path_match"=&gt;"message", "match_mapping_type"=&gt;"string", "mapping"=&gt;{"type"=&gt;"text", "norms"=&gt;false}}}, {"string_fields"=&gt;{"match"=&gt;"*", "match_mapping_type"=&gt;"string", "mapping"=&gt;{"type"=&gt;"text", "norms"=&gt;false, "fields"=&gt;{"keyword"=&gt;{"type"=&gt;"keyword", "ignore_above"=&gt;256}}}}}], "properties"=&gt;{"@timestamp"=&gt;{"type"=&gt;"date"}, "@version"=&gt;{"type"=&gt;"keyword"}, "geoip"=&gt;{"dynamic"=&gt;true, "properties"=&gt;{"ip"=&gt;{"type"=&gt;"ip"}, "location"=&gt;{"type"=&gt;"geo_point"}, "latitude"=&gt;{"type"=&gt;"half_float"}, "longitude"=&gt;{"type"=&gt;"half_float"}}}}}}}
[INFO ] 2019-08-02 18:29:21.769 [Ruby-0-Thread-7: :1] elasticsearch - Attempting to install template {:manage_template=&gt;{"index_patterns"=&gt;"logstash-*", "version"=&gt;60001, "settings"=&gt;{"index.refresh_interval"=&gt;"5s", "number_of_shards"=&gt;1}, "mappings"=&gt;{"dynamic_templates"=&gt;[{"message_field"=&gt;{"path_match"=&gt;"message", "match_mapping_type"=&gt;"string", "mapping"=&gt;{"type"=&gt;"text", "norms"=&gt;false}}}, {"string_fields"=&gt;{"match"=&gt;"*", "match_mapping_type"=&gt;"string", "mapping"=&gt;{"type"=&gt;"text", "norms"=&gt;false, "fields"=&gt;{"keyword"=&gt;{"type"=&gt;"keyword", "ignore_above"=&gt;256}}}}}], "properties"=&gt;{"@timestamp"=&gt;{"type"=&gt;"date"}, "@version"=&gt;{"type"=&gt;"keyword"}, "geoip"=&gt;{"dynamic"=&gt;true, "properties"=&gt;{"ip"=&gt;{"type"=&gt;"ip"}, "location"=&gt;{"type"=&gt;"geo_point"}, "latitude"=&gt;{"type"=&gt;"half_float"}, "longitude"=&gt;{"type"=&gt;"half_float"}}}}}}}
[INFO ] 2019-08-02 18:29:21.771 [Ruby-0-Thread-9: :1] elasticsearch - Attempting to install template {:manage_template=&gt;{"index_patterns"=&gt;"logstash-*", "version"=&gt;60001, "settings"=&gt;{"index.refresh_interval"=&gt;"5s", "number_of_shards"=&gt;1}, "mappings"=&gt;{"dynamic_templates"=&gt;[{"message_field"=&gt;{"path_match"=&gt;"message", "match_mapping_type"=&gt;"string", "mapping"=&gt;{"type"=&gt;"text", "norms"=&gt;false}}}, {"string_fields"=&gt;{"match"=&gt;"*", "match_mapping_type"=&gt;"string", "mapping"=&gt;{"type"=&gt;"text", "norms"=&gt;false, "fields"=&gt;{"keyword"=&gt;{"type"=&gt;"keyword", "ignore_above"=&gt;256}}}}}], "properties"=&gt;{"@timestamp"=&gt;{"type"=&gt;"date"}, "@version"=&gt;{"type"=&gt;"keyword"}, "geoip"=&gt;{"dynamic"=&gt;true, "properties"=&gt;{"ip"=&gt;{"type"=&gt;"ip"}, "location"=&gt;{"type"=&gt;"geo_point"}, "latitude"=&gt;{"type"=&gt;"half_float"}, "longitude"=&gt;{"type"=&gt;"half_float"}}}}}}}
[WARN ] 2019-08-02 18:29:21.871 [[main]-pipeline-manager] LazyDelegatingGauge - A gauge metric of an unknown type (org.jruby.specialized.RubyArrayOneObject) has been create for key: cluster_uuids. This may result in invalid serialization.  It is recommended to log an issue to the responsible developer/development team.
[INFO ] 2019-08-02 18:29:21.878 [[main]-pipeline-manager] javapipeline - Starting pipeline {:pipeline_id=&gt;"main", "pipeline.workers"=&gt;1, "pipeline.batch.size"=&gt;125, "pipeline.batch.delay"=&gt;50, "pipeline.max_inflight"=&gt;125, :thread=&gt;"#&lt;Thread:0x470bf1ca run&gt;"}
[INFO ] 2019-08-02 18:29:22.351 [[main]-pipeline-manager] javapipeline - Pipeline started {"pipeline.id"=&gt;"main"}
[INFO ] 2019-08-02 18:29:22.721 [Ruby-0-Thread-1: /usr/share/logstash/lib/bootstrap/environment.rb:6] agent - Pipelines running {:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]}
[INFO ] 2019-08-02 18:29:23.798 [Api Webserver] agent - Successfully started Logstash API endpoint {:port=&gt;9600}
/usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/rufus-scheduler-3.0.9/lib/rufus/scheduler/cronline.rb:77: warning: constant ::Fixnum is deprecated
/usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/rufus-scheduler-3.0.9/lib/rufus/scheduler/cronline.rb:77: warning: constant ::Fixnum is deprecated
/usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/rufus-scheduler-3.0.9/lib/rufus/scheduler/cronline.rb:77: warning: constant ::Fixnum is deprecated
[INFO ] 2019-08-02 18:30:02.333 [Ruby-0-Thread-22: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/rufus-scheduler-3.0.9/lib/rufus/scheduler/jobs.rb:284] jdbc - (0.042932s) SELECT * FROM pg_stat_user_indexes
[INFO ] 2019-08-02 18:30:02.340 [Ruby-0-Thread-23: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/rufus-scheduler-3.0.9/lib/rufus/scheduler/jobs.rb:331] jdbc - (0.043178s) SELECT * FROM pg_stat_user_tables
[INFO ] 2019-08-02 18:30:02.340 [Ruby-0-Thread-24: :1] jdbc - (0.036469s) SELECT * FROM pg_stat_database
...
</code></pre>
<p>Se o Logstash não mostrar nenhum erro e registrar com êxito as linhas Selecionadas (<code>SELECT</code>) dos três bancos de dados, suas métricas serão enviadas ao Elasticsearch. Se você obtiver um erro, verifique todos os valores no arquivo de configuração para garantir que a máquina na qual você está executando o Logstash possa se conectar ao banco de dados gerenciado.</p>

<p>O Logstash continuará importando os dados em horários especificados. Você pode pará-lo com segurança pressionando <code>CTRL+C</code>.</p>

<p>Como mencionado anteriormente, quando iniciado como um serviço, o Logstash executa automaticamente todos os arquivos de configuração encontrados em <code>/etc/logstash/conf.d</code> em segundo plano. Execute o seguinte comando para iniciá-lo como um serviço:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo systemctl start logstash
</li></ul></code></pre>
<p>Neste passo, você executou o Logstash para verificar se ele pode se conectar ao seu banco de dados e coletar dados. Em seguida, você visualizará e explorará alguns dos dados estatísticos no Kibana.</p>

<h2 id="passo-4-—-explorando-os-dados-importados-no-kibana">Passo 4 — Explorando os Dados Importados no Kibana</h2>

<p>Nesta seção, você verá como você pode explorar os dados estatísticos que descrevem o desempenho do seu banco de dados no Kibana.</p>

<p>No seu navegador, navegue até a instalação do Kibana que você configurou como pré-requisito. Você verá a página de boas-vindas padrão.</p>

<p><img src="https://assets.digitalocean.com/articles/postgres_managed_elk/step4a.png" alt="Kibana - Default Welcome Page"></p>

<p>Para interagir com os índices do Elasticsearch no Kibana, você precisará criar um padrão de índice ou Index patterns. <em>Index patterns</em> especificam em quais índices o Kibana deve operar. Para criar um, pressione o último ícone (chave inglesa) na barra lateral vertical esquerda para abrir a página <strong>Management</strong>. Em seguida, no menu esquerdo, clique em <strong>Index Patterns</strong> abaixo de <strong>Kibana</strong>.. Você verá uma caixa de diálogo para criar um padrão de índice.</p>

<p><img src="https://assets.digitalocean.com/articles/postgres_managed_elk/step4b.png" alt="Kibana - Add Index Pattern"></p>

<p>Aqui estão listados os três índices para os quais o Logstash está enviando estatísticas. Digite <code>pg_stat_database</code> na caixa de entrada <strong>Index Pattern</strong> e pressione <strong>Next step</strong>. Você será solicitado a selecionar um campo que armazene tempo, para poder restringir seus dados posteriormente por um intervalo de tempo. No menu suspenso, selecione <code>@timestamp</code>.</p>

<p><img src="https://assets.digitalocean.com/articles/postgres_managed_elk/step4c.png" alt="Kibana - Index Pattern Timestamp Field"></p>

<p>Clique em <strong>Create index pattern</strong> para concluir a criação do padrão de índice. Agora você poderá explorá-lo usando o Kibana. Para criar uma visualização, clique no segundo ícone na barra lateral e, em seguida, em <strong>Create new visualization</strong>. Selecione a visualização <strong>Line</strong> quando o formulário aparecer e escolha o padrão de índice que você acabou de criar (<code>pg_stat_database</code>). Você verá uma visualização vazia.</p>

<p><img src="https://assets.digitalocean.com/articles/postgres_managed_elk/step4d.png" alt="Kibana - Empty Visualisation"></p>

<p>Na parte central da tela está o gráfico resultante — o painel do lado esquerdo governa sua geração a partir da qual você pode definir os dados para os eixos X e Y. No lado superior direito da tela, está o seletor de período. A menos que você escolha especificamente outro intervalo ao configurar os dados, esse intervalo será mostrado no gráfico.</p>

<p>Agora você visualizará o número médio de tuplas de dados inseridas (<code>INSERT</code>) em minutos no intervalo especificado. Clique em <strong>Y-Axis</strong> em <strong>Metrics</strong> no painel à esquerda para expandir. Selecione <em>Average</em> ou média como <strong>Aggregation</strong> e selecione <code>tup_inserted</code> como <strong>Field</strong> ou campo. Isso preencherá o eixo Y do gráfico com os valores médios.</p>

<p>Em seguida, clique em <strong>X-Axis</strong> em <strong>Buckets</strong>. Para <strong>Aggregation</strong>, escolha <strong>Date Histogram</strong>. <code>@timestamp</code> deve ser selecionado automaticamente como o <strong>Field</strong>. Em seguida, pressione o botão play azul na parte superior do painel para gerar seu gráfico. Se o seu banco de dados for novo e não for usado, você não verá nada ainda. Em todos os casos, no entanto, você verá um retrato preciso do uso do banco de dados.</p>

<p>O Kibana suporta muitas outras formas de visualização — você pode explorar outras formas na <a href="https://www.elastic.co/guide/en/kibana/current/tutorial-visualizing.html">documentação do Kibana</a>. Você também pode adicionar os dois índices restantes, mencionados no Passo 2 ao Kibana para poder visualizá-los também.</p>

<p>Neste passo, você aprendeu como visualizar alguns dos dados estatísticos do PostgreSQL, usando o Kibana.</p>

<h2 id="passo-5-—-opcional-fazendo-benchmark-usando-pgbench">Passo 5 — (Opcional) Fazendo Benchmark Usando pgbench</h2>

<p>Se você ainda não trabalhou no seu banco de dados fora deste tutorial, você pode concluir esta etapa para criar visualizações mais interessantes usando o pgbench para fazer benchmark do seu banco de dados. O pgbench executará os mesmos comandos SQL repetidamente, simulando o uso do banco de dados no mundo real por um cliente real.</p>

<p>Você primeiro precisará instalar o pgbench executando o seguinte comando:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">sudo apt install postgresql-contrib -y
</li></ul></code></pre>
<p>Como o pgbench irá inserir e atualizar dados de teste, você precisará criar um banco de dados separado para ele. Para fazer isso, vá para a guia <strong>Users &amp; Databases</strong> no Painel de Controle do seu banco de dados gerenciado e role para baixo até a seção <strong>Databases</strong>. Digite <code>pgbench</code> como o nome do novo banco de dados e pressione <strong>Save</strong>. Você passará esse nome, bem como as informações de host, porta e nome de usuário para o pgbench.</p>

<p><img src="https://assets.digitalocean.com/articles/postgres_managed_elk/step5a.png" alt="Accessing Databases section in DO control panel"></p>

<p>Antes de executar de fato o <code>pgbench</code>, você precisará executá-lo com a flag <code>-i</code> para inicializar seu banco de dados:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">pgbench -h <span class="highlight">host</span> -p <span class="highlight">port</span> -U <span class="highlight">username</span> -i pgbench
</li></ul></code></pre>
<p>Você precisará substituir <code><span class="highlight">host</span></code> pelo seu endereço de host, <code><span class="highlight">port</span></code> pela porta à qual você pode se conectar ao seu banco de dados e <code><span class="highlight">username</span></code> com o nome do usuário do banco de dados. Você pode encontrar todos esses valores no painel de controle do seu banco de dados gerenciado.</p>

<p>Observe que o <code>pgbench</code> não possui um argumento de senha; em vez disso, você será solicitado sempre que executá-lo.</p>

<p>A saída terá a seguinte aparência:</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>NOTICE:  table "pgbench_history" does not exist, skipping
NOTICE:  table "pgbench_tellers" does not exist, skipping
NOTICE:  table "pgbench_accounts" does not exist, skipping
NOTICE:  table "pgbench_branches" does not exist, skipping
creating tables...
100000 of 100000 tuples (100%) done (elapsed 0.16 s, remaining 0.00 s)
vacuum...
set primary keys...
done.
</code></pre>
<p>O <code>pgbench</code> criou quatro tabelas que serão usadas para o benchmarking e as preencheu com algumas linhas de exemplo. Agora você poderá executar benchmarks.</p>

<p>Os dois argumentos mais importantes que limitam por quanto tempo o benchmark será executado são <code>-t</code>, que especifica o número de transações a serem concluídas, e <code>-T</code>, que define por quantos segundos o benchmark deve ser executado. Essas duas opções são mutuamente exclusivas. No final de cada benchmark, você receberá estatísticas, como o número de transações por segundo (<code>tps</code>).</p>

<p>Agora, inicie um benchmark que durará 30 segundos executando o seguinte comando:</p>
<pre class="code-pre command"><code langs=""><ul class="prefixed"><li class="line" prefix="$">pgbench -h <span class="highlight">host</span> -p <span class="highlight">port</span> -U <span class="highlight">username</span> pgbench <span class="highlight">-T 30</span>
</li></ul></code></pre>
<p>A saída será semelhante a:</p>
<pre class="code-pre "><code langs=""><div class="secondary-code-label " title="Output">Output</div>starting vacuum...end.
transaction type: &lt;builtin: TPC-B (sort of)&gt;
scaling factor: 1
query mode: simple
number of clients: 1
number of threads: 1
duration: 30 s
number of transactions actually processed: 7602
latency average = 3.947 ms
tps = 253.382298 (including connections establishing)
tps = 253.535257 (excluding connections establishing)
</code></pre>
<p>Nesta saída, você vê as informações gerais sobre o benchmark, como o número total de transações executadas. O efeito desses benchmarks é que as estatísticas enviadas pelo Logstash para o Elasticsearch refletirão esse número, o que tornará as visualizações no Kibana mais interessantes e mais próximas dos gráficos do mundo real. Você pode executar o comando anterior mais algumas vezes e talvez alterar a duração.</p>

<p>Quando terminar, vá para o Kibana e clique em <strong>Refresh</strong> no canto superior direito. Agora você verá uma linha diferente da anterior, que mostra o número de <code>INSERT</code>s. Sinta-se à vontade para alterar o intervalo de tempo dos dados mostrados, alterando os valores no seletor posicionado acima do botão de atualização. Aqui está como o gráfico pode se apresentar após vários benchmarks de duração variável:</p>

<p><img src="https://assets.digitalocean.com/articles/postgres_managed_elk/step5b.png" alt="Kibana - Visualization After Benchmarks"></p>

<p>Você usou o pgbench para fazer benchmark em seu banco de dados e avaliou os gráficos resultantes no Kibana.</p>

<h2 id="conclusão">Conclusão</h2>

<p>Agora você tem a pilha Elastic instalada em seu servidor e configurada para coletar regularmente dados estatísticos do banco de dados PostgreSQL gerenciado. Você pode analisar e visualizar os dados usando o Kibana, ou algum outro software adequado, que o ajudará a reunir informações valiosas e correlações do mundo real sobre o desempenho do seu banco de dados.</p>

<p>Para obter mais informações sobre o que você pode fazer com o banco de dados gerenciado do PostgreSQL, visite a <a href="https://www.digitalocean.com/docs/databases/">documentação de produto</a>.</p>
